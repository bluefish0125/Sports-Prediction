{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a015969b-c296-4b92-a0ea-99d0dd5df390",
   "metadata": {},
   "source": [
    "- [1. Instructions](#1)\n",
    "- [2. Importing Functions and Packages](#2)\n",
    "- [3. Retrieving Datasets from GitHub and Update](#3)\n",
    "    - [3.1 Ranking Data](#3_1)\n",
    "    - [3.2 Game Stats](#3_2)\n",
    "    - [3.3 Odds Data](#3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b002d-7571-40dd-9431-b4061e0d43af",
   "metadata": {},
   "source": [
    "## 1. Instructions <a id='1'></a>\n",
    "\n",
    "For Ranking Data:\n",
    "- Connect to GitHub in py file\n",
    "- Retrive data and add missing data\n",
    "- Add it back to original address\n",
    "\n",
    "For Game Stats:\n",
    "\n",
    "For Odds Data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3822d1-0412-4bce-b1be-be28d11a7350",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Importing Functions and Packages <a id='2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27480a3-c621-4922-848e-e4ced2ef3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.sessions import Session\n",
    "from nba_api.stats.endpoints import playergamelog\n",
    "from nba_api.stats.static import teams\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "import base64\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "from nba_api.stats.endpoints import playergamelog, leaguedashteamstats, teamyearbyyearstats\n",
    "from nba_api.stats.library.parameters import SeasonAll\n",
    "from nba_api.stats.static import players, teams\n",
    "import datetime\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7dbaf2a-a884-4856-880f-da010a345deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to maintain uniform naming schemes across datasets\n",
    "mapping = {'Brooklyn Nets': 'BRK', 'Golden State Warriors': 'GSW', 'Los Angeles Lakers': 'LAL',\n",
    "       'Milwaukee Bucks': 'MIL', 'Boston Celtics': 'BOS', 'Charlotte Hornets': 'CHO',\n",
    "       'Chicago Bulls': 'CHI', 'Cleveland Cavaliers': 'CLE', 'Denver Nuggets': 'DEN',\n",
    "       'Detroit Pistons': 'DET', 'Houston Rockets': 'HOU', 'Indiana Pacers': 'IND',\n",
    "       'Memphis Grizzlies': 'MEM', 'Minnesota Timberwolves': 'MIN',\n",
    "       'New Orleans Pelicans': 'NOP', 'New York Knicks': 'NYK', 'Oklahoma City Thunder': 'OKC',\n",
    "       'Orlando Magic': 'ORL', 'Philadelphia 76ers': 'PHI', 'Phoenix Suns': 'PHO',\n",
    "       'Portland Trail Blazers': 'POR', 'Sacramento Kings': 'SAC', 'San Antonio Spurs': 'SAS',\n",
    "       'Toronto Raptors': 'TOR', 'Utah Jazz': 'UTA', 'Washington Wizards': 'WAS',\n",
    "       'Atlanta Hawks': 'ATL', 'Dallas Mavericks': 'DAL', 'LA Clippers': 'LAC', 'Miami Heat': 'MIA'}\n",
    "\n",
    "def merge_with_suffixes(dataframes, names, keys):\n",
    "    \"\"\"Merging different sets of data of the same season together\"\"\"\n",
    "    suffixed_dfs = []\n",
    "    for df, name in zip(dataframes, names):\n",
    "        # Suffix non-key columns only\n",
    "        suffixed_cols = {col: f\"{col}_{name}\" if col not in keys else col for col in df.columns}\n",
    "        suffixed_dfs.append(df.rename(columns=suffixed_cols))\n",
    "\n",
    "    merged_df = suffixed_dfs[0]\n",
    "    for df in suffixed_dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on=keys, how='inner')\n",
    "    return merged_df\n",
    "    \n",
    "\n",
    "def extracting_today_data(from_date=None, season='2023-24', season_type='Regular Season', data_type='Base', delay=5):\n",
    "    year_start = season[:4]\n",
    "    year_end = str(int(year_start)+1)\n",
    "    season_ = year_start + \"-\" + year_end[2:]\n",
    "    season = year_start + \"_\" + year_end\n",
    "    if from_date == None:\n",
    "        path_today = f\"/Users/liqingyang/Documents/GitHub/sports_trading/sports_betting/nba_api/data/teams_stats/{season}/base_{season}.csv\"\n",
    "        from_date = pd.read_csv(path_today, parse_dates=['Date'])['Date'].max().date()\n",
    "\n",
    "    season_end = datetime.date.today() - datetime.timedelta(days=1)\n",
    "    \n",
    "    current_date = from_date\n",
    "    all_data = []\n",
    "\n",
    "    unsuccessful_dates = []\n",
    "    \n",
    "    while current_date <= season_end:\n",
    "        date_str = current_date.strftime('%m/%d/%Y')\n",
    "        \n",
    "        try:\n",
    "            daily_stats = leaguedashteamstats.LeagueDashTeamStats(\n",
    "                measure_type_detailed_defense=data_type,\n",
    "                season=season_,\n",
    "                season_type_all_star=season_type,\n",
    "                date_to_nullable=date_str\n",
    "            ).get_data_frames()[0]\n",
    "            daily_stats['Date'] = date_str\n",
    "            all_data.append(daily_stats)\n",
    "            print(f\"Data fetched for {date_str}\")\n",
    "        except Exception as e:\n",
    "            unsuccessful_dates += [date_str]\n",
    "            print(f\"Error fetching data for {date_str}: {e}\")\n",
    "        time.sleep(delay)\n",
    "        current_date += datetime.timedelta(days=1)\n",
    "        \n",
    "    full_season_data = pd.concat(all_data, ignore_index=True)\n",
    "    return full_season_data, unsuccessful_dates\n",
    "\n",
    "def getting_stats(delay=5, retrieving_from=None):\n",
    "    \"\"\"Getting cumulative season stats for each game\"\"\"\n",
    "    track_start='2023'\n",
    "    season_end='2024'\n",
    "    if retrieving_from is None:\n",
    "        retrieving_from = datetime.now() - timedelta(seconds=delay)\n",
    "    \n",
    "    base, unsuccessful_dates_base = extracting_today_data(from_date=retrieving_from, data_type='Base', delay=delay)\n",
    "    advanced, unsuccessful_dates_advanced = extracting_today_data(from_date=retrieving_from, data_type='Advanced', delay=delay)\n",
    "    misc, unsuccessful_dates_misc = extracting_today_data(from_date=retrieving_from, data_type='Misc', delay=delay)\n",
    "    four_factors, unsuccessful_dates_four_factors = extracting_today_data(from_date=retrieving_from, data_type='Four Factors', delay=delay)\n",
    "    scoring, unsuccessful_dates_scoring = extracting_today_data(from_date=retrieving_from, data_type='Scoring', delay=delay)\n",
    "    opponent, unsuccessful_dates_opponent = extracting_today_data(from_date=retrieving_from, data_type='Opponent', delay=delay)\n",
    "    defense, unsuccessful_dates_defense = extracting_today_data(from_date=retrieving_from, data_type='Defense', delay=delay)\n",
    "\n",
    "    year_start = track_start[:4]\n",
    "    year_end = season_end[:4]\n",
    "    season_ = year_start + \"_\" + year_end[2:]\n",
    "    season = year_start + \"_\" + year_end\n",
    "\n",
    "    datas = [base, advanced, misc, four_factors, scoring, opponent, defense]\n",
    "    \n",
    "    unsuccessful_dates_lst = [unsuccessful_dates_base, unsuccessful_dates_advanced, unsuccessful_dates_misc, unsuccessful_dates_four_factors, unsuccessful_dates_scoring, unsuccessful_dates_opponent, unsuccessful_dates_defense]\n",
    "    datas_names = [\"base\", \"advanced\", \"misc\", \"four_factors\",\n",
    "               \"scoring\", \"opponent\", \"defense\"]\n",
    "    columns_to_exclude = ['TEAM_NAME', 'GP', 'W', 'L', 'W_PCT', 'MIN']\n",
    "    others = [advanced, misc, four_factors, scoring, opponent, defense]\n",
    "    others = [i[i.columns[~i.columns.isin(columns_to_exclude)]] for i in others]\n",
    "    datas = [base] + others\n",
    "    \n",
    "    merge_keys = ['Date', 'TEAM_ID']\n",
    "    merged_df = merge_with_suffixes(datas, datas_names, merge_keys) \n",
    "    merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def process(df):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['Teams'] = df['TEAM_NAME_base'].map(mapping)\n",
    "    del df['TEAM_NAME_base']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6c955-3863-466c-b236-b5e7a380bc7f",
   "metadata": {},
   "source": [
    "## 3. Retrieving Datasets from GitHub and Update <a id='3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a84f4-a891-46d6-99ef-0f60aa96bb82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.1 Ranking Data <a id='3_1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b8a106f6-a552-464a-81af-ec6e467f4c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated already\n"
     ]
    }
   ],
   "source": [
    "# Your personal access token and repo details\n",
    "token = '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'\n",
    "username = 'bluefish0125'\n",
    "repo = 'Sports-Betting'\n",
    "path_to_file = 'nba_api/data/teams_stats/processed_cum_2018_2024.csv'\n",
    "\n",
    "# GitHub API URL for your file\n",
    "url = f'https://api.github.com/repos/{username}/{repo}/contents/{path_to_file}'\n",
    "\n",
    "# Hvae to use raw file\n",
    "raw_url = 'https://raw.githubusercontent.com/bluefish0125/Sports-Betting/main/nba_api/data/teams_stats/processed_cum_2018_2024.csv'\n",
    "# Send a GET request with headers including your personal access token for authentication\n",
    "response = requests.get(raw_url, headers=headers)\n",
    "if response.status_code == 200: # 200 means successful\n",
    "    processed_data = pd.read_csv(StringIO(response.text), index_col=0)\n",
    "    processed_data['Date'] = pd.to_datetime(processed_data['Date'], format='mixed')    \n",
    "    max_day = processed_data['Date'].max().date()\n",
    "    next_day = max_day + datetime.timedelta(days=1)\n",
    "    \n",
    "else:\n",
    "    print(f\"Failed to retrieve the CSV file. Status Code: {response.status_code}\")\n",
    "\n",
    "today = pd.DataFrame()\n",
    "if (next_day == datetime.date.today()):\n",
    "    print(\"Updated already\")\n",
    "else:\n",
    "    print(\"Getting Stats\")\n",
    "    print(next_day)\n",
    "    today = getting_stats(retrieving_from=next_day).iloc[:, 1:]\n",
    "    today = process(today)\n",
    "nba = pd.concat([processed_data, today], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7159b448-5520-40c3-bbd7-42e97ee8332e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-04-05 00:00:00')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ef8ec141-99f6-4513-b743-9a89d466950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = nba[nba['Date'] < nba['Date'].max()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d2ac87c9-90b8-4e76-bc39-3fc4db06416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Convert the DataFrame to CSV\n",
    "csv_content = nba.to_csv()\n",
    "content_encoded = base64.b64encode(csv_content.encode('utf-8')).decode('utf-8')\n",
    "new_path_to_file = 'nba_api/data/teams_stats/processed_cum_2018_2024.csv'\n",
    "# new_path_to_file = 'data_pipeline/test_file/test_file_1.csv'\n",
    "new_url = f'https://api.github.com/repos/{username}/{repo}/contents/{new_path_to_file}'\n",
    "# Prepare headers\n",
    "headers = {\n",
    "    'Authorization': f'token {token}',\n",
    "    'Accept': 'application/vnd.github.v3+json',\n",
    "}\n",
    "\n",
    "# Fetch the file from GitHub to get its SHA\n",
    "response = requests.get(new_url, headers=headers)\n",
    "data = response.json()\n",
    "sha = data['sha']\n",
    "\n",
    "# Create the payload with the new content and the SHA\n",
    "payload = {\n",
    "    'message': 'Update CSV file',\n",
    "    'content': content_encoded,\n",
    "    'sha': sha,\n",
    "    'branch': 'main',  # specify the branch if not 'main'\n",
    "}\n",
    "\n",
    "# Make a PUT request to update the file\n",
    "response = requests.put(new_url, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print('File updated successfully.')\n",
    "else:\n",
    "    print('Failed to update the file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008cc73-4ad6-46bf-9fc4-bce13cebc25d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Modifying Data in GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "50606416-6e98-4dc7-8ca2-aeab8280e96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Convert the DataFrame to CSV\n",
    "csv_content = nba.to_csv()\n",
    "content_encoded = base64.b64encode(csv_content.encode('utf-8')).decode('utf-8')\n",
    "new_path_to_file = 'nba_api/data/teams_stats/processed_cum_2018_2024.csv'\n",
    "new_url = f'https://api.github.com/repos/{username}/{repo}/contents/{new_path_to_file}'\n",
    "# Prepare headers\n",
    "headers = {\n",
    "    'Authorization': f'token {token}',\n",
    "    'Accept': 'application/vnd.github.v3+json',\n",
    "}\n",
    "\n",
    "# Fetch the file from GitHub to get its SHA\n",
    "response = requests.get(new_url, headers=headers)\n",
    "data = response.json()\n",
    "sha = data['sha']\n",
    "\n",
    "# Create the payload with the new content and the SHA\n",
    "payload = {\n",
    "    'message': 'Update CSV file',\n",
    "    'content': content_encoded,\n",
    "    'sha': sha,\n",
    "    'branch': 'main',  # specify the branch if not 'main'\n",
    "}\n",
    "\n",
    "# Make a PUT request to update the file\n",
    "response = requests.put(url, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print('File updated successfully.')\n",
    "else:\n",
    "    print('Failed to update the file.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b1bac321-4f28-4479-b272-dad121a30b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create the new file. Status Code: 422 Response: {'message': 'Invalid request.\\n\\n\"sha\" wasn\\'t supplied.', 'documentation_url': 'https://docs.github.com/rest/repos/contents#create-or-update-file-contents'}\n"
     ]
    }
   ],
   "source": [
    "csv_content = nba.to_csv()\n",
    "content_encoded = base64.b64encode(csv_content.encode('utf-8')).decode('utf-8')\n",
    "new_path_to_file = 'data_pipeline/test_file/test_file_1.csv'\n",
    "new_url = f'https://api.github.com/repos/{username}/{repo}/contents/{new_path_to_file}'\n",
    "\n",
    "# Prepare headers for authentication\n",
    "headers = {\n",
    "    'Authorization': f'token {token}',\n",
    "    'Accept': 'application/vnd.github.v3+json',\n",
    "}\n",
    "\n",
    "# Create the payload with the new content\n",
    "payload = {\n",
    "    'message': 'Add new CSV file',\n",
    "    'content': content_encoded,\n",
    "    'branch': 'main',  # specify the branch if not 'main'\n",
    "}\n",
    "\n",
    "# Make a PUT request to upload the file\n",
    "response = requests.put(new_url, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code == 201:\n",
    "    print('New file created successfully.')\n",
    "else:\n",
    "    print(f'Failed to create the new file. Status Code: {response.status_code} Response: {response.json()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d600a1-43eb-4e14-a24e-d558d96d2434",
   "metadata": {},
   "source": [
    "### 3.2 Game Stats <a id='3_2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d65d25-0c63-41b0-9432-123d147b5bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98d05fb4-bca7-430d-b23d-2bccdafdb997",
   "metadata": {},
   "source": [
    "### 3.3 Odds Data <a id='3_3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "452ec68a-88c3-4dcb-bd4d-54ed20ad933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "pd.reset_option('display.max_rows')\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "mapping = {'Brooklyn Nets': 'BRK', 'Golden State Warriors': 'GSW', 'Los Angeles Lakers': 'LAL',\n",
    "       'Milwaukee Bucks': 'MIL', 'Boston Celtics': 'BOS', 'Charlotte Hornets': 'CHO',\n",
    "       'Chicago Bulls': 'CHI', 'Cleveland Cavaliers': 'CLE', 'Denver Nuggets': 'DEN',\n",
    "       'Detroit Pistons': 'DET', 'Houston Rockets': 'HOU', 'Indiana Pacers': 'IND',\n",
    "       'Memphis Grizzlies': 'MEM', 'Minnesota Timberwolves': 'MIN',\n",
    "       'New Orleans Pelicans': 'NOP', 'New York Knicks': 'NYK', 'Oklahoma City Thunder': 'OKC',\n",
    "       'Orlando Magic': 'ORL', 'Philadelphia 76ers': 'PHI', 'Phoenix Suns': 'PHO',\n",
    "       'Portland Trail Blazers': 'POR', 'Sacramento Kings': 'SAC', 'San Antonio Spurs': 'SAS',\n",
    "       'Toronto Raptors': 'TOR', 'Utah Jazz': 'UTA', 'Washington Wizards': 'WAS',\n",
    "       'Atlanta Hawks': 'ATL', 'Dallas Mavericks': 'DAL', 'Los Angeles Clippers': 'LAC', 'Miami Heat': 'MIA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b9f350e-ff2e-406a-859e-08efef652028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col\n",
    "\n",
    "def add_col(df, col_name):\n",
    "    return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a3bcd30-cda7-4418-aeae-cc1db292e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/liqingyang/Documents/GitHub/sports_trading/sports_betting/nba_api/data/teams_stats/processed_cum_2018_2024.csv\"\n",
    "df = pd.read_csv(folder_path, index_col=0)\n",
    "df = df.reset_index(drop=True)\n",
    "date_series = pd.to_datetime(df['Date'])\n",
    "cur_max = date_series.max().strftime(\"%Y-%m-%d\")\n",
    "df = df[df['Date'] >= cur_max]\n",
    "df['date_next'] = add_col(df, 'Date')\n",
    "date_prediction = (date_series.max() + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "df['date_next'].fillna(date_prediction, inplace=True)\n",
    "dates = df['date_next'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c65c4568-3dd4-46f9-a082-f16d1c049338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time zones\n",
    "dates_utc = []\n",
    "est_timezone = pytz.timezone('America/New_York')  # Eastern Standard Time (EST)\n",
    "utc_timezone = pytz.timezone('UTC')\n",
    "\n",
    "threshold_value = pd.to_datetime('2020-06-27T03:55:00Z')\n",
    "\n",
    "full = []\n",
    "for date in dates:\n",
    "    date = date[:10]\n",
    "    # Create a datetime object for the given time in EST\n",
    "    est_time = datetime.strptime(f'{date} 7:00 PM', '%Y-%m-%d %I:%M %p')\n",
    "    est_time = est_timezone.localize(est_time)\n",
    "\n",
    "    # Convert EST time to UTC\n",
    "    utc_time = est_time.astimezone(utc_timezone)\n",
    "    if utc_time >= threshold_value:\n",
    "        final_time = utc_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        dates_utc.append(final_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12e05b6b-198e-4105-b9b9-fce358e3c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'dc34ee156925bf51d4a4c33c87d440fc'\n",
    "SPORT = 'basketball_nba'\n",
    "REGION = 'us'\n",
    "MARKET = 'h2h'\n",
    "FORMAT = 'decimal'\n",
    "full = []\n",
    "# adjust number of dates \n",
    "DATES = dates_utc\n",
    "for DATE in DATES:\n",
    "    response = requests.get(f'https://api.the-odds-api.com/v4/historical/sports/{SPORT}/odds',\n",
    "        params={\n",
    "            'api_key': KEY,\n",
    "            'regions': REGION,\n",
    "            'markets': MARKET,\n",
    "            'oddsFormat': FORMAT,\n",
    "            'date': DATE,\n",
    "        }\n",
    "    ).json()\n",
    "    for i in range(len(response['data'])):\n",
    "        # [Timestamp, good team, evil team, fanduel odds good team wins, draftkings odds, caesars odds]\n",
    "        #best_odds = [[None,None,None,None,float('-inf')] for _ in range(2)]\n",
    "        bookmakers = response['data'][i]['bookmakers']\n",
    "        for index, data in enumerate(bookmakers):\n",
    "            best_odds = [[None,None,None,None,float('-inf')] for _ in range(2)]\n",
    "            if response['data'][i]['bookmakers'][index]['title'] in [\"FanDuel\", \"BetMGM\", \"DraftKings\"]:\n",
    "                for outcome in range(2):\n",
    "                    odds = response['data'][i]['bookmakers'][index]['markets'][0]['outcomes'][outcome]['price']\n",
    "                    current_odds = best_odds[outcome][4]\n",
    "                    best_odds[outcome][0] = response['timestamp']\n",
    "                    best_odds[outcome][1] = response['data'][i]['id']\n",
    "                    best_odds[outcome][2] = response['data'][i]['bookmakers'][index]['title']\n",
    "                    best_odds[outcome][3] = response['data'][i]['bookmakers'][index]['markets'][0]['outcomes'][outcome]['name']\n",
    "                    best_odds[outcome][4] = odds\n",
    "                full.extend(best_odds)\n",
    "\n",
    "timestamp = []\n",
    "Id = []\n",
    "sportsbook = []\n",
    "team = []\n",
    "odds = []\n",
    "for i in range(len(full)):\n",
    "    timestamp.append(full[i][0])\n",
    "    Id.append(full[i][1])\n",
    "    sportsbook.append(full[i][2])\n",
    "    team.append(full[i][3])\n",
    "    odds.append(full[i][4])\n",
    "df = pd.DataFrame({\"Timestamp\": timestamp,\"Id\": Id, \"Sportsbook\": sportsbook, \"Team\": team, \"Odds\": odds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52d55500-d8ef-488c-8421-1de4fdfb9d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ids with less than 6 rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3098c246e193f7b9dc6468b660dd6e47',\n",
       " '6e41e3b197f4ed18b9be5aed40f6e0fb',\n",
       " '827de5fba5998e542dd701dd0bd5c916',\n",
       " '85a837d69d683f938e2de8bf20623b2c',\n",
       " 'c42ec787f2f26bbbd665aefd40337733',\n",
       " 'd257ef9200525ae1a09743eeb8a2f90c']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('Id')\n",
    "group_sizes = grouped.size()\n",
    "\n",
    "# Filter groups with less than 6 rows\n",
    "ids_with_less_than_six_rows = group_sizes[group_sizes < 6].index.tolist()\n",
    "\n",
    "print(\"Ids with less than 6 rows:\")\n",
    "\n",
    "ids_with_less_than_six_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e74d453-7489-4481-9fb9-467741b304cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = []\n",
    "for Id in ids_with_less_than_six_rows:\n",
    "    group = df[df['Id'] == Id]\n",
    "    sportsbooks = [\"FanDuel\", \"BetMGM\", \"DraftKings\"]\n",
    "    \n",
    "    # check which sportsbook is missing\n",
    "    present_sportsbooks = group['Sportsbook'].unique()\n",
    "    missing_sportsbooks = [sb for sb in sportsbooks if sb not in present_sportsbooks][0]\n",
    "\n",
    "    teams = group['Team'].unique()\n",
    "    for team in teams:\n",
    "        missing = [None, None, None, None, float('-inf')]\n",
    "        # calculate average odds \n",
    "        missing[0] = group['Timestamp'].iloc[0]\n",
    "        missing[1] = Id\n",
    "        missing[2] = missing_sportsbooks\n",
    "        missing[3] = team\n",
    "        missing[4] = round(group[group['Team'] == team]['Odds'].mean(), 2)\n",
    "        miss.append(missing)\n",
    "missing_df = pd.DataFrame(miss, columns=['Timestamp', 'Id', 'Sportsbook', 'Team', 'Odds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1aab90c6-d7ec-478d-ae32-5b20490ab34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Id</th>\n",
       "      <th>Sportsbook</th>\n",
       "      <th>Team</th>\n",
       "      <th>Odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>3098c246e193f7b9dc6468b660dd6e47</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>3098c246e193f7b9dc6468b660dd6e47</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Sacramento Kings</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>6e41e3b197f4ed18b9be5aed40f6e0fb</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>6e41e3b197f4ed18b9be5aed40f6e0fb</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>827de5fba5998e542dd701dd0bd5c916</td>\n",
       "      <td>FanDuel</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>827de5fba5998e542dd701dd0bd5c916</td>\n",
       "      <td>FanDuel</td>\n",
       "      <td>Oklahoma City Thunder</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>85a837d69d683f938e2de8bf20623b2c</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>85a837d69d683f938e2de8bf20623b2c</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Los Angeles Clippers</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>c42ec787f2f26bbbd665aefd40337733</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Indiana Pacers</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>c42ec787f2f26bbbd665aefd40337733</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>d257ef9200525ae1a09743eeb8a2f90c</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-04-06T22:55:38Z</td>\n",
       "      <td>d257ef9200525ae1a09743eeb8a2f90c</td>\n",
       "      <td>BetMGM</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp                                Id Sportsbook  \\\n",
       "0   2024-04-06T22:55:38Z  3098c246e193f7b9dc6468b660dd6e47     BetMGM   \n",
       "1   2024-04-06T22:55:38Z  3098c246e193f7b9dc6468b660dd6e47     BetMGM   \n",
       "2   2024-04-06T22:55:38Z  6e41e3b197f4ed18b9be5aed40f6e0fb     BetMGM   \n",
       "3   2024-04-06T22:55:38Z  6e41e3b197f4ed18b9be5aed40f6e0fb     BetMGM   \n",
       "4   2024-04-06T22:55:38Z  827de5fba5998e542dd701dd0bd5c916    FanDuel   \n",
       "5   2024-04-06T22:55:38Z  827de5fba5998e542dd701dd0bd5c916    FanDuel   \n",
       "6   2024-04-06T22:55:38Z  85a837d69d683f938e2de8bf20623b2c     BetMGM   \n",
       "7   2024-04-06T22:55:38Z  85a837d69d683f938e2de8bf20623b2c     BetMGM   \n",
       "8   2024-04-06T22:55:38Z  c42ec787f2f26bbbd665aefd40337733     BetMGM   \n",
       "9   2024-04-06T22:55:38Z  c42ec787f2f26bbbd665aefd40337733     BetMGM   \n",
       "10  2024-04-06T22:55:38Z  d257ef9200525ae1a09743eeb8a2f90c     BetMGM   \n",
       "11  2024-04-06T22:55:38Z  d257ef9200525ae1a09743eeb8a2f90c     BetMGM   \n",
       "\n",
       "                     Team  Odds  \n",
       "0           Brooklyn Nets  3.28  \n",
       "1        Sacramento Kings  1.36  \n",
       "2           Chicago Bulls  3.40  \n",
       "3           Orlando Magic  1.34  \n",
       "4       Charlotte Hornets  3.95  \n",
       "5   Oklahoma City Thunder  1.27  \n",
       "6     Cleveland Cavaliers  2.45  \n",
       "7    Los Angeles Clippers  1.58  \n",
       "8          Indiana Pacers  1.87  \n",
       "9              Miami Heat  1.96  \n",
       "10       Dallas Mavericks  1.33  \n",
       "11        Houston Rockets  3.42  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7494949-6cc7-4980-a384-9bd00c959bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = pd.concat([df, missing_df], ignore_index=True)\n",
    "concat = concat.sort_values(by=['Timestamp', 'Id'])\n",
    "concat = concat.reset_index(drop=True)\n",
    "full = concat.merge(concat,\n",
    "               left_on=['Timestamp','Id', 'Sportsbook'],\n",
    "               right_on = ['Timestamp','Id', 'Sportsbook'])\n",
    "full = full.drop(full[full['Team_x'] == full['Team_y']].index)\n",
    "full = full.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "efb19cb7-4340-46c0-9022-f9c09a336eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "full['Timestamp'] = pd.to_datetime(full['Timestamp'])\n",
    "\n",
    "utc_timezone = pytz.utc\n",
    "est_timezone = pytz.timezone('US/Eastern')\n",
    "\n",
    "full['Timestamp'] = full['Timestamp'].dt.tz_convert(est_timezone)\n",
    "full['Timestamp'] = full['Timestamp'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "full['Team_x'] = full['Team_x'].map(mapping)\n",
    "full['Team_y'] = full['Team_y'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0df42861-5fd3-4117-927a-cc0176208d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fanduel = full[full['Sportsbook'] == 'FanDuel']\n",
    "columns = fanduel.columns\n",
    "columns = ['Timestamp', 'Id', 'Sportsbook', 'Team_x', 'Fanduel_odds_x','Team_y', 'Fanduel_odds_y']\n",
    "fanduel.columns = columns\n",
    "fanduel = fanduel.drop('Sportsbook', axis=1)\n",
    "\n",
    "draftkings = full[full['Sportsbook'] == 'DraftKings']\n",
    "columns = draftkings.columns\n",
    "columns = ['Timestamp', 'Id', 'Sportsbook', 'Team_x', 'Draftkings_odds_x','Team_y', 'Draftkings_odds_y']\n",
    "draftkings.columns = columns\n",
    "draftkings = draftkings.drop('Sportsbook', axis=1)\n",
    "\n",
    "betMGM = full[full['Sportsbook'] == 'BetMGM']\n",
    "columns = betMGM.columns\n",
    "columns = ['Timestamp', 'Id', 'Sportsbook', 'Team_x', 'BetMGM_odds_x','Team_y', 'BetMGM_odds_y']\n",
    "betMGM.columns = columns\n",
    "betMGM = betMGM.drop('Sportsbook', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "416dbb0d-ea52-4a94-b8f1-a187ababfd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fd_dk = pd.merge(fanduel, draftkings, on=['Timestamp', 'Id', 'Team_x', 'Team_y'], how='left')\n",
    "\n",
    "# Merge the result with betMGM DataFrame\n",
    "final = pd.merge(merged_fd_dk, betMGM, on=['Timestamp', 'Id', 'Team_x', 'Team_y'], how='left')\n",
    "columns = final.columns\n",
    "columns = ['Timestamp', 'Id', 'Teams_x', 'Fanduel_odds_x','Teams_y', 'Fanduel_odds_y', 'Draftkings_odds_x', 'Draftkings_odds_y', 'BetMGM_odds_x', 'BetMGM_odds_y']\n",
    "final.columns = columns\n",
    "final = final.drop('Id', axis=1)\n",
    "\n",
    "order = ['Timestamp', 'Teams_x', 'Fanduel_odds_x','Draftkings_odds_x', 'BetMGM_odds_x', 'Teams_y', 'Fanduel_odds_y','Draftkings_odds_y', 'BetMGM_odds_y']\n",
    "final = final[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757242bb-fddc-483d-97b9-b9690b536910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
