{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645ed76a-94c1-42a8-8163-86a007822ed7",
   "metadata": {},
   "source": [
    "- [1. Import Packages and Functions](#1)\n",
    "- [2. Assembling Datasets](#2)\n",
    "- [3. Model Buildings](#3)\n",
    "    - [3.1 Random Forest Classifier](#3_1)\n",
    "    - [3.2 AdaBoost Tree](#3_2)\n",
    "    - [3.3 XGBoost (Extreme Gradient Boosting)](#3_3)\n",
    "    - [3.4 CatBoost](#3_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad23ea1-bbd4-4bc3-8c47-a800aa227cf3",
   "metadata": {},
   "source": [
    "## 1. Import Packages and Functions <a id='1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e43b99bb-6c43-46c4-8d4c-f8d8feb8fb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (1.2 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from catboost) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from catboost) (1.26.3)\n",
      "Requirement already satisfied: pandas>=0.24 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from catboost) (1.11.1)\n",
      "Collecting plotly (from catboost)\n",
      "  Downloading plotly-5.20.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->catboost) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->catboost) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Collecting tenacity>=6.2.0 (from plotly->catboost)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Downloading catboost-1.2.3-cp311-cp311-macosx_11_0_universal2.whl (26.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.20.0-py3-none-any.whl (15.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, graphviz, plotly, catboost\n",
      "Successfully installed catboost-1.2.3 graphviz-0.20.3 plotly-5.20.0 tenacity-8.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ce3910da-dfae-4f48-8ba9-ad615f91594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost) (1.26.3)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost) (1.11.1)\n",
      "Downloading xgboost-2.0.3-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdde3890-2c94-4bff-b59f-e67a858436ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import desired packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import statsmodels.api as sm\n",
    "import gc\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, TimeSeriesSplit, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, RidgeClassifier, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, silhouette_score, f1_score, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, SequentialFeatureSelector, RFE\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331d7021-555b-416a-b5fe-54ce6668687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(team):\n",
    "    team['target'] = team['won'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def rest_days(team):\n",
    "    team['date_time'] = pd.to_datetime(team['date'])\n",
    "    team['rest'] = (team['date_time'] - team['date_time'].shift(1)).dt.days\n",
    "    team['rest'] = team['rest'].fillna(0)\n",
    "    team['rest'] = team['rest'].astype(int)\n",
    "    del team['date_time']\n",
    "    return team\n",
    "\n",
    "def winrate(team):\n",
    "    total = team['Wins'] + team['Losses']\n",
    "    total_opp = team['Wins_opp'] + team['Losses_opp']\n",
    "    team['winrate'] = team['Wins'] / total\n",
    "    team['winrate_opp'] = team['Wins_opp'] / total_opp\n",
    "    return team\n",
    "\n",
    "def differential(team):\n",
    "    team['differential'] = team['Total'] - team['Total_opp']\n",
    "    return team\n",
    "\n",
    "def find_team_exp_average_5(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=5, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_exp_average_9(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=9, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_exp_average_12(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=12, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_15(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(15).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_10(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_5(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(5).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_3(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(3).mean()\n",
    "    return rolling\n",
    "\n",
    "def rolling(data):\n",
    "    df_rolling_3 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_3 = df_rolling_3.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_3)\n",
    "    df_rolling_5 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_5 = df_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_5)\n",
    "    df_rolling_10 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_10 = df_rolling_10.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_10)\n",
    "    df_rolling_15 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_15 = df_rolling_15.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_15)\n",
    "    df_exp_rolling_5 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_5 = df_exp_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_5)\n",
    "    df_exp_rolling_9 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_9 = df_exp_rolling_9.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_9)\n",
    "    df_exp_rolling_12 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_12 = df_exp_rolling_12.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_12)\n",
    "    exp_rolling_columns_5 = [f\"{col}_exp_5\" for col in df_exp_rolling_5.columns]\n",
    "    exp_rolling_columns_9 = [f\"{col}_exp_9\" for col in df_exp_rolling_9.columns]\n",
    "    exp_rolling_columns_12 = [f\"{col}_exp_12\" for col in df_exp_rolling_12.columns]\n",
    "    rolling_columns_15 = [f\"{col}_15\" for col in df_rolling_15.columns]\n",
    "    rolling_columns_10 = [f\"{col}_10\" for col in df_rolling_10.columns]\n",
    "    rolling_columns_5 = [f\"{col}_5\" for col in df_rolling_5.columns]\n",
    "    rolling_columns_3 = [f\"{col}_3\" for col in df_rolling_3.columns]\n",
    "    df_exp_rolling_12.columns = exp_rolling_columns_12\n",
    "    df_exp_rolling_9.columns = exp_rolling_columns_9\n",
    "    df_exp_rolling_5.columns = exp_rolling_columns_5\n",
    "    df_rolling_15.columns = rolling_columns_15\n",
    "    df_rolling_10.columns = rolling_columns_10\n",
    "    df_rolling_5.columns = rolling_columns_5\n",
    "    df_rolling_3.columns = rolling_columns_3\n",
    "    df = pd.concat([data, df_rolling_3, df_rolling_5, df_rolling_10, df_rolling_15,df_exp_rolling_5,df_exp_rolling_9, df_exp_rolling_12], axis=1)\n",
    "    return df\n",
    "\n",
    "def ratio(feature):\n",
    "    feature_opp = 'OPP_' + str(feature)\n",
    "    free = nba[feature] / nba[feature_opp]\n",
    "    return free\n",
    "\n",
    "def ratios(nba):\n",
    "    regard = []\n",
    "    disregard = [col for col in nba.columns if \"OPP_\" in col]\n",
    "    for col in disregard:\n",
    "        col = col[4:100]\n",
    "        if col in nba.columns:\n",
    "            regard.append(col)\n",
    "    nba_ratio = nba[regard].apply(ratio)\n",
    "    nba_ratios_columns = [f\"{col}_ratio\" for col in nba_ratio.columns]\n",
    "    nba_ratio.columns\n",
    "    return regard\n",
    "\n",
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col\n",
    "\n",
    "def add_col(df, col_name):\n",
    "    return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
    "\n",
    "def date_change(datetime_str):\n",
    "    # Parse the datetime string into a datetime object\n",
    "    datetime_obj = datetime.strptime(datetime_str, '%m/%d/%Y')\n",
    "\n",
    "    # Format the datetime object into a new string structure\n",
    "    new_datetime_str = datetime_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    return new_datetime_str\n",
    "\n",
    "def haircut(df, date):\n",
    "    df[date] = df[date].str[:10]\n",
    "    return df\n",
    "\n",
    "def convert_date_format(df):\n",
    "    # Create a boolean mask to identify values in the \"m/d/y\" format\n",
    "    mask = df['Date'].str.contains(r'\\d{1,2}/\\d{1,2}/\\d{2}')\n",
    "    \n",
    "    # Apply the conversion only to values that match the mask\n",
    "    df.loc[mask, 'Date'] = nba.loc[mask, 'Date'].apply(date_change)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ca2ea-d328-4ae7-b3dc-5d7d6236b1fa",
   "metadata": {},
   "source": [
    "## 2. Assembling Dataset <a id='3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "afc3c03b-ad79-4004-9c68-4810026f6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/liqingyang/Documents/GitHub/sports_trading/sports_betting/data/raw_data/NBA_2018_2024.csv\"\n",
    "df = pd.read_csv(folder_path, index_col=0)\n",
    "\n",
    "folder_path = \"/Users/liqingyang/Documents/GitHub/sports_trading/sports_betting/nba_api/data/teams_stats/processed_cumulative_season_stats_2019_2024.csv\"\n",
    "nba = pd.read_csv(folder_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "82909c77-8a61-4ba2-b849-b555ade61839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nba dataframe does not include the 2018 season\n",
    "df = df[~df['season'].isin([2018])]\n",
    "df = df.reset_index(drop=True)\n",
    "df = haircut(df, 'date')\n",
    "\n",
    "# rename nba columns to match df\n",
    "nba = haircut(nba, 'Date')\n",
    "nba = convert_date_format(nba)\n",
    "nba.rename(columns={'Date': 'date_next', 'Teams':'Teams_x'}, inplace=True)\n",
    "\n",
    "# construct winrate for team\n",
    "df = winrate(df)\n",
    "# construct differential points\n",
    "df = differential(df)\n",
    "# construct target\n",
    "df = df.groupby(\"Teams\", group_keys=False).apply(add_target)\n",
    "# construct resting\n",
    "df = df.groupby([\"Teams\",'season'], group_keys=False).apply(rest_days)\n",
    "# games yet to play are 2\n",
    "df.loc[pd.isnull(df['target']), 'target'] = 2\n",
    "# convert win/loss to 1/0\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "# remove metadata and target for df\n",
    "removed = ['target', 'date', 'Teams_opp', 'Teams',\n",
    "           'season','won', 'Wins', 'Losses', \n",
    "           'Wins_opp', 'Losses_opp']\n",
    "valid_columns = df.columns[~df.columns.isin(removed)]\n",
    "\n",
    "# scale the data\n",
    "scaler = MinMaxScaler()\n",
    "df[valid_columns] = scaler.fit_transform(df[valid_columns])\n",
    "\n",
    "# construct rolling features to df\n",
    "df = rolling(df).copy()\n",
    "df = df.dropna()\n",
    "\n",
    "# remove metadata for nba ranking \n",
    "removed = ['date_next', 'Teams_x']\n",
    "valid_columns = nba.columns[~nba.columns.isin(removed)]\n",
    "\n",
    "# scale the ranking data\n",
    "scaler = MinMaxScaler()\n",
    "nba[valid_columns] = scaler.fit_transform(nba[valid_columns])\n",
    "\n",
    "# construct current game metadata\n",
    "df['home_next'] = add_col(df, 'home')\n",
    "df['team_next_opp'] = add_col(df, 'Teams_opp')\n",
    "df['date_next'] = add_col(df, 'date')\n",
    "df = df.copy()\n",
    "\n",
    "# merge stats from opposing teams\n",
    "full = df.merge(df,\n",
    "               left_on=['Teams', 'date_next'],\n",
    "               right_on = ['team_next_opp', 'date_next'])\n",
    "full['date_next_dt'] = pd.to_datetime(full['date_next'])\n",
    "full['date_next_prev'] = (full['date_next_dt']-timedelta(days=1)).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# merge stats from nba dataframe\n",
    "nba_renamed_home = nba.rename(columns={col: col + '_for_home' for col in nba.columns if col not in ['Teams_x', 'date_next']})\n",
    "nba_renamed_away = nba.rename(columns={col: col + '_for_away' for col in nba.columns if col not in ['Teams_x', 'date_next']})\n",
    "\n",
    "for_home = pd.merge(full, nba_renamed_home, left_on=['Teams_x', 'date_next_prev'],right_on=['Teams_x', 'date_next'], how='left')\n",
    "complete = pd.merge(for_home, nba_renamed_away, left_on=['team_next_opp_x', 'date_next_prev'], right_on=['Teams_x', 'date_next'], how='left')\n",
    "complete = complete.dropna()\n",
    "\n",
    "# remove metadata and useless data\n",
    "disregard = list(complete.columns[complete.dtypes == 'object']) \n",
    "disregard = disregard + [\"home_opp_5_x\",\"target_y\", \n",
    "                         \"Wins_x\", \"Losses_x\", \"Wins_opp_x\", \n",
    "                         \"Losses_opp_x\", \"season_x\" , \"won_x\" , \n",
    "                         \"home_5_x\" ,\"home_10_x\" ,\"season_5_x\", \n",
    "                         \"season_10_x\" , \"Wins_y\" , \"Losses_y\" , \n",
    "                         \"Wins_opp_y\" , \"Losses_opp_y\" , \"season_y\" , \n",
    "                         \"won_y\" ,\"home_5_y\", \"home_10_y\",\"season_5_y\", \n",
    "                         \"season_10_y\",\"home_opp_5_y\", \"home_opp_10_y\"]\n",
    "regard = complete.columns[~complete.columns.isin(disregard)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c7c73899-50cc-4225-b905-780aae2ea483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to exclude January 2024 - March 2024 data from dataframe to use for out of sample testing\n",
    "complete = complete[~complete['date_next'].str.contains('2024-03')|complete['date_next'].str.contains('2024-02')|complete['date_next'].str.contains('2024-01')]\n",
    "complete = complete.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d8ec856d-60a6-4383-9fd3-5cd389de6874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp_x</th>\n",
       "      <th>fg_x</th>\n",
       "      <th>fga_x</th>\n",
       "      <th>fg%_x</th>\n",
       "      <th>3p_x</th>\n",
       "      <th>3pa_x</th>\n",
       "      <th>3p%_x</th>\n",
       "      <th>ft_x</th>\n",
       "      <th>fta_x</th>\n",
       "      <th>ft%_x</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_OREB_RANK_opponent_for_away</th>\n",
       "      <th>OPP_DREB_RANK_opponent_for_away</th>\n",
       "      <th>OPP_REB_RANK_opponent_for_away</th>\n",
       "      <th>OPP_AST_RANK_opponent_for_away</th>\n",
       "      <th>OPP_TOV_RANK_opponent_for_away</th>\n",
       "      <th>OPP_STL_RANK_opponent_for_away</th>\n",
       "      <th>OPP_BLK_RANK_opponent_for_away</th>\n",
       "      <th>OPP_PF_RANK_opponent_for_away</th>\n",
       "      <th>OPP_PFD1_opponent_for_away</th>\n",
       "      <th>OPP_PTS_RANK_opponent_for_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.705742</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.452781</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.674355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.187581</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.373206</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.126779</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.399522</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.420440</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.361244</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.267788</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.592944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10407</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.401035</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.763908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.430622</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.322122</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.321574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.576555</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.447607</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.773406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10410</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.440191</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.441138</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.796472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10411</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.406699</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.309185</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.660787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.206897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10412 rows × 2560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mp_x      fg_x     fga_x     fg%_x      3p_x     3pa_x     3p%_x  \\\n",
       "0      0.00  0.727273  0.516667  0.705742  0.407407  0.350000  0.452781   \n",
       "1      0.00  0.250000  0.483333  0.188995  0.259259  0.533333  0.187581   \n",
       "2      0.00  0.363636  0.400000  0.373206  0.037037  0.133333  0.126779   \n",
       "3      0.00  0.454545  0.516667  0.399522  0.407407  0.383333  0.420440   \n",
       "4      0.00  0.363636  0.416667  0.361244  0.222222  0.316667  0.267788   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "10407  0.00  0.477273  0.450000  0.473684  0.333333  0.316667  0.401035   \n",
       "10408  0.00  0.522727  0.583333  0.430622  0.444444  0.566667  0.322122   \n",
       "10409  0.25  0.704545  0.650000  0.576555  0.555556  0.516667  0.447607   \n",
       "10410  0.00  0.409091  0.383333  0.440191  0.518519  0.483333  0.441138   \n",
       "10411  0.00  0.340909  0.316667  0.406699  0.370370  0.483333  0.309185   \n",
       "\n",
       "           ft_x     fta_x     ft%_x  ...  OPP_OREB_RANK_opponent_for_away  \\\n",
       "0      0.404762  0.431373  0.674355  ...                         0.448276   \n",
       "1      0.428571  0.470588  0.648575  ...                         0.379310   \n",
       "2      0.595238  0.607843  0.720488  ...                         0.620690   \n",
       "3      0.166667  0.196078  0.582090  ...                         0.896552   \n",
       "4      0.285714  0.333333  0.592944  ...                         0.827586   \n",
       "...         ...       ...       ...  ...                              ...   \n",
       "10407  0.404762  0.392157  0.763908  ...                         0.655172   \n",
       "10408  0.142857  0.254902  0.321574  ...                         0.482759   \n",
       "10409  0.190476  0.176471  0.773406  ...                         0.517241   \n",
       "10410  0.357143  0.333333  0.796472  ...                         0.137931   \n",
       "10411  0.309524  0.333333  0.660787  ...                         0.655172   \n",
       "\n",
       "       OPP_DREB_RANK_opponent_for_away  OPP_REB_RANK_opponent_for_away  \\\n",
       "0                             0.517241                        0.448276   \n",
       "1                             0.206897                        0.310345   \n",
       "2                             0.137931                        0.310345   \n",
       "3                             0.655172                        0.655172   \n",
       "4                             0.517241                        0.655172   \n",
       "...                                ...                             ...   \n",
       "10407                         0.482759                        0.586207   \n",
       "10408                         0.620690                        0.620690   \n",
       "10409                         0.000000                        0.000000   \n",
       "10410                         0.655172                        0.517241   \n",
       "10411                         0.413793                        0.551724   \n",
       "\n",
       "       OPP_AST_RANK_opponent_for_away  OPP_TOV_RANK_opponent_for_away  \\\n",
       "0                            0.724138                        0.758621   \n",
       "1                            0.448276                        0.206897   \n",
       "2                            0.241379                        1.000000   \n",
       "3                            0.862069                        0.241379   \n",
       "4                            0.758621                        0.172414   \n",
       "...                               ...                             ...   \n",
       "10407                        0.172414                        0.172414   \n",
       "10408                        0.793103                        0.586207   \n",
       "10409                        0.241379                        0.724138   \n",
       "10410                        0.758621                        0.206897   \n",
       "10411                        0.379310                        0.310345   \n",
       "\n",
       "       OPP_STL_RANK_opponent_for_away  OPP_BLK_RANK_opponent_for_away  \\\n",
       "0                            0.862069                        0.517241   \n",
       "1                            0.206897                        0.724138   \n",
       "2                            0.241379                        0.655172   \n",
       "3                            0.413793                        0.448276   \n",
       "4                            0.344828                        0.310345   \n",
       "...                               ...                             ...   \n",
       "10407                        0.241379                        0.758621   \n",
       "10408                        0.172414                        0.689655   \n",
       "10409                        0.310345                        0.103448   \n",
       "10410                        0.068966                        0.517241   \n",
       "10411                        0.000000                        0.896552   \n",
       "\n",
       "       OPP_PF_RANK_opponent_for_away  OPP_PFD1_opponent_for_away  \\\n",
       "0                           0.793103                    0.206897   \n",
       "1                           0.206897                    0.965517   \n",
       "2                           0.137931                    0.931034   \n",
       "3                           0.620690                    0.137931   \n",
       "4                           0.620690                    0.448276   \n",
       "...                              ...                         ...   \n",
       "10407                       0.379310                    0.000000   \n",
       "10408                       0.241379                    0.724138   \n",
       "10409                       0.310345                    0.793103   \n",
       "10410                       0.448276                    0.551724   \n",
       "10411                       0.586207                    0.137931   \n",
       "\n",
       "       OPP_PTS_RANK_opponent_for_away  \n",
       "0                            0.689655  \n",
       "1                            0.241379  \n",
       "2                            0.206897  \n",
       "3                            0.758621  \n",
       "4                            0.655172  \n",
       "...                               ...  \n",
       "10407                        0.965517  \n",
       "10408                        0.689655  \n",
       "10409                        0.103448  \n",
       "10410                        0.413793  \n",
       "10411                        0.206897  \n",
       "\n",
       "[10412 rows x 2560 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_value_columns = [column for column, is_equal in columns_with_same_values.items() if is_equal]\n",
    "complete_cleaning = complete.copy()\n",
    "# Dropping duplicated columns\n",
    "complete_cleaning = complete_cleaning.T.drop_duplicates(keep='first').T\n",
    "for column in complete_cleaning.columns:\n",
    "    complete_cleaning[column] = pd.to_numeric(complete_cleaning[column], errors='ignore')\n",
    "complete_cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108b0b5-daec-42bb-94be-ed4746557a0e",
   "metadata": {},
   "source": [
    "#### Getting ranking spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4cebcd3b-ee73-4b2a-a89f-ffa41dc7bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
      "/var/folders/4m/qh070ww90rqgmcw604kkdt8r0000gn/T/ipykernel_45322/2962696270.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp_x</th>\n",
       "      <th>fg_x</th>\n",
       "      <th>fga_x</th>\n",
       "      <th>fg%_x</th>\n",
       "      <th>3p_x</th>\n",
       "      <th>3pa_x</th>\n",
       "      <th>3p%_x</th>\n",
       "      <th>ft_x</th>\n",
       "      <th>fta_x</th>\n",
       "      <th>ft%_x</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_FT_PCT_RANK_opponent_spread</th>\n",
       "      <th>OPP_OREB_RANK_opponent_spread</th>\n",
       "      <th>OPP_DREB_RANK_opponent_spread</th>\n",
       "      <th>OPP_REB_RANK_opponent_spread</th>\n",
       "      <th>OPP_AST_RANK_opponent_spread</th>\n",
       "      <th>OPP_TOV_RANK_opponent_spread</th>\n",
       "      <th>OPP_STL_RANK_opponent_spread</th>\n",
       "      <th>OPP_BLK_RANK_opponent_spread</th>\n",
       "      <th>OPP_PF_RANK_opponent_spread</th>\n",
       "      <th>OPP_PTS_RANK_opponent_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.705742</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.452781</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.674355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.793103</td>\n",
       "      <td>-0.206897</td>\n",
       "      <td>-0.413793</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.172414</td>\n",
       "      <td>-0.413793</td>\n",
       "      <td>-0.241379</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>-0.241379</td>\n",
       "      <td>-0.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.188995</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.187581</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.724138</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>-0.137931</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>-0.034483</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.373206</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.126779</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>-0.827586</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.399522</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.420440</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>-0.482759</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.361244</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.267788</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.592944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310345</td>\n",
       "      <td>-0.206897</td>\n",
       "      <td>-0.379310</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.517241</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>-0.103448</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>-0.482759</td>\n",
       "      <td>-0.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10407</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.401035</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.763908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172414</td>\n",
       "      <td>-0.275862</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>-0.103448</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>-0.034483</td>\n",
       "      <td>-0.103448</td>\n",
       "      <td>-0.137931</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>-0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.430622</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.322122</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.321574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>-0.482759</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.517241</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>-0.379310</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>-0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.576555</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.447607</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.773406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068966</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>-0.620690</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>-0.172414</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10410</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.440191</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.441138</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.796472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>-0.172414</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>-0.448276</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10411</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.406699</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.309185</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.660787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>-0.379310</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.586207</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10412 rows × 2646 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mp_x      fg_x     fga_x     fg%_x      3p_x     3pa_x     3p%_x  \\\n",
       "0      0.00  0.727273  0.516667  0.705742  0.407407  0.350000  0.452781   \n",
       "1      0.00  0.250000  0.483333  0.188995  0.259259  0.533333  0.187581   \n",
       "2      0.00  0.363636  0.400000  0.373206  0.037037  0.133333  0.126779   \n",
       "3      0.00  0.454545  0.516667  0.399522  0.407407  0.383333  0.420440   \n",
       "4      0.00  0.363636  0.416667  0.361244  0.222222  0.316667  0.267788   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "10407  0.00  0.477273  0.450000  0.473684  0.333333  0.316667  0.401035   \n",
       "10408  0.00  0.522727  0.583333  0.430622  0.444444  0.566667  0.322122   \n",
       "10409  0.25  0.704545  0.650000  0.576555  0.555556  0.516667  0.447607   \n",
       "10410  0.00  0.409091  0.383333  0.440191  0.518519  0.483333  0.441138   \n",
       "10411  0.00  0.340909  0.316667  0.406699  0.370370  0.483333  0.309185   \n",
       "\n",
       "           ft_x     fta_x     ft%_x  ...  OPP_FT_PCT_RANK_opponent_spread  \\\n",
       "0      0.404762  0.431373  0.674355  ...                        -0.793103   \n",
       "1      0.428571  0.470588  0.648575  ...                        -0.724138   \n",
       "2      0.595238  0.607843  0.720488  ...                         0.310345   \n",
       "3      0.166667  0.196078  0.582090  ...                         0.655172   \n",
       "4      0.285714  0.333333  0.592944  ...                        -0.310345   \n",
       "...         ...       ...       ...  ...                              ...   \n",
       "10407  0.404762  0.392157  0.763908  ...                        -0.172414   \n",
       "10408  0.142857  0.254902  0.321574  ...                         0.034483   \n",
       "10409  0.190476  0.176471  0.773406  ...                        -0.068966   \n",
       "10410  0.357143  0.333333  0.796472  ...                         0.586207   \n",
       "10411  0.309524  0.333333  0.660787  ...                         0.137931   \n",
       "\n",
       "       OPP_OREB_RANK_opponent_spread  OPP_DREB_RANK_opponent_spread  \\\n",
       "0                          -0.206897                      -0.413793   \n",
       "1                           0.310345                       0.517241   \n",
       "2                           0.206897                       0.379310   \n",
       "3                           0.068966                       0.344828   \n",
       "4                          -0.206897                      -0.379310   \n",
       "...                              ...                            ...   \n",
       "10407                      -0.275862                       0.034483   \n",
       "10408                       0.068966                      -0.482759   \n",
       "10409                       0.448276                       1.000000   \n",
       "10410                       0.448276                       0.068966   \n",
       "10411                      -0.379310                       0.482759   \n",
       "\n",
       "       OPP_REB_RANK_opponent_spread  OPP_AST_RANK_opponent_spread  \\\n",
       "0                         -0.344828                     -0.172414   \n",
       "1                          0.482759                      0.551724   \n",
       "2                          0.344828                      0.517241   \n",
       "3                          0.344828                      0.034483   \n",
       "4                         -0.344828                     -0.517241   \n",
       "...                             ...                           ...   \n",
       "10407                     -0.103448                      0.517241   \n",
       "10408                     -0.344828                     -0.517241   \n",
       "10409                      1.000000                      0.758621   \n",
       "10410                      0.241379                     -0.172414   \n",
       "10411                      0.275862                      0.448276   \n",
       "\n",
       "       OPP_TOV_RANK_opponent_spread  OPP_STL_RANK_opponent_spread  \\\n",
       "0                         -0.413793                     -0.241379   \n",
       "1                         -0.137931                      0.793103   \n",
       "2                         -0.827586                      0.103448   \n",
       "3                          0.103448                      0.413793   \n",
       "4                          0.827586                     -0.103448   \n",
       "...                             ...                           ...   \n",
       "10407                     -0.034483                     -0.103448   \n",
       "10408                      0.241379                      0.517241   \n",
       "10409                     -0.620690                      0.413793   \n",
       "10410                      0.724138                      0.275862   \n",
       "10411                      0.241379                      0.413793   \n",
       "\n",
       "       OPP_BLK_RANK_opponent_spread  OPP_PF_RANK_opponent_spread  \\\n",
       "0                          0.379310                    -0.241379   \n",
       "1                         -0.034483                     0.689655   \n",
       "2                         -0.344828                     0.482759   \n",
       "3                          0.551724                    -0.482759   \n",
       "4                          0.344828                    -0.482759   \n",
       "...                             ...                          ...   \n",
       "10407                     -0.137931                     0.206897   \n",
       "10408                     -0.379310                     0.137931   \n",
       "10409                      0.689655                    -0.172414   \n",
       "10410                     -0.448276                     0.379310   \n",
       "10411                     -0.344828                    -0.586207   \n",
       "\n",
       "       OPP_PTS_RANK_opponent_spread  \n",
       "0                         -0.379310  \n",
       "1                          0.620690  \n",
       "2                          0.448276  \n",
       "3                          0.137931  \n",
       "4                         -0.448276  \n",
       "...                             ...  \n",
       "10407                     -0.482759  \n",
       "10408                     -0.103448  \n",
       "10409                      0.896552  \n",
       "10410                      0.379310  \n",
       "10411                      0.517241  \n",
       "\n",
       "[10412 rows x 2646 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = [i for i in complete_cleaning.columns if 'RANK' in i]\n",
    "ranks_home = [i for i in ranks if 'for_home' in i]\n",
    "ranks_away = [i for i in ranks if 'for_away' in i]\n",
    "spread_columns_names = [i[:-4] for i in ranks_home]\n",
    "temp = complete_cleaning.copy()\n",
    "for i in spread_columns_names:\n",
    "    complete_cleaning[i[:-4] + 'spread'] = complete_cleaning[i + 'home'] - complete_cleaning[i + 'away']\n",
    "complete_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3376aa43-5cdf-43dd-9d81-94e42cf8728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete is dataframe with both ranking and stats \n",
    "home = complete_cleaning[complete_cleaning['home_x'] == 1]\n",
    "home = home.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f1e0a143-f6d9-403e-9ce4-25513bf81035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp_x</th>\n",
       "      <th>fg_x</th>\n",
       "      <th>fga_x</th>\n",
       "      <th>fg%_x</th>\n",
       "      <th>3p_x</th>\n",
       "      <th>3pa_x</th>\n",
       "      <th>3p%_x</th>\n",
       "      <th>ft_x</th>\n",
       "      <th>fta_x</th>\n",
       "      <th>ft%_x</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_FT_PCT_RANK_opponent_spread</th>\n",
       "      <th>OPP_OREB_RANK_opponent_spread</th>\n",
       "      <th>OPP_DREB_RANK_opponent_spread</th>\n",
       "      <th>OPP_REB_RANK_opponent_spread</th>\n",
       "      <th>OPP_AST_RANK_opponent_spread</th>\n",
       "      <th>OPP_TOV_RANK_opponent_spread</th>\n",
       "      <th>OPP_STL_RANK_opponent_spread</th>\n",
       "      <th>OPP_BLK_RANK_opponent_spread</th>\n",
       "      <th>OPP_PF_RANK_opponent_spread</th>\n",
       "      <th>OPP_PTS_RANK_opponent_spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.705742</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.452781</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.674355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.793103</td>\n",
       "      <td>-0.206897</td>\n",
       "      <td>-0.413793</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.172414</td>\n",
       "      <td>-0.413793</td>\n",
       "      <td>-0.241379</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>-0.241379</td>\n",
       "      <td>-0.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.373206</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.126779</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>-0.827586</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.516746</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.291074</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.618725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>-0.379310</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.619617</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.358344</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.773406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>-0.241379</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>-0.517241</td>\n",
       "      <td>-0.137931</td>\n",
       "      <td>-0.724138</td>\n",
       "      <td>-0.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.564593</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.452781</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.521031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.137931</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>-0.103448</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>-0.482759</td>\n",
       "      <td>-0.586207</td>\n",
       "      <td>-0.448276</td>\n",
       "      <td>-0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5206</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.566986</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.260026</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.660787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>-0.448276</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.758621</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>-0.413793</td>\n",
       "      <td>-0.689655</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>-0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.313397</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.364812</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.750339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.586207</td>\n",
       "      <td>-0.448276</td>\n",
       "      <td>-0.068966</td>\n",
       "      <td>-0.241379</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>-0.724138</td>\n",
       "      <td>-0.275862</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>-0.379310</td>\n",
       "      <td>-0.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.478469</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.390686</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.548168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034483</td>\n",
       "      <td>-0.068966</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>-0.241379</td>\n",
       "      <td>-0.517241</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>-0.137931</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.528708</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.386805</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>-0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>-0.517241</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>-0.206897</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.406699</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.309185</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.660787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>-0.379310</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.586207</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5211 rows × 2474 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mp_x      fg_x     fga_x     fg%_x      3p_x     3pa_x     3p%_x  \\\n",
       "0     0.00  0.727273  0.516667  0.705742  0.407407  0.350000  0.452781   \n",
       "1     0.00  0.363636  0.400000  0.373206  0.037037  0.133333  0.126779   \n",
       "2     0.00  0.613636  0.600000  0.516746  0.296296  0.400000  0.291074   \n",
       "3     0.25  0.590909  0.433333  0.619617  0.259259  0.266667  0.358344   \n",
       "4     0.00  0.590909  0.500000  0.564593  0.592593  0.550000  0.452781   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "5206  0.00  0.545455  0.433333  0.566986  0.296296  0.450000  0.260026   \n",
       "5207  0.50  0.522727  0.783333  0.313397  0.407407  0.450000  0.364812   \n",
       "5208  0.00  0.568182  0.583333  0.478469  0.407407  0.416667  0.390686   \n",
       "5209  0.00  0.659091  0.650000  0.528708  0.444444  0.466667  0.386805   \n",
       "5210  0.00  0.340909  0.316667  0.406699  0.370370  0.483333  0.309185   \n",
       "\n",
       "          ft_x     fta_x     ft%_x  ...  OPP_FT_PCT_RANK_opponent_spread  \\\n",
       "0     0.404762  0.431373  0.674355  ...                        -0.793103   \n",
       "1     0.595238  0.607843  0.720488  ...                         0.310345   \n",
       "2     0.500000  0.568627  0.618725  ...                         0.793103   \n",
       "3     0.428571  0.411765  0.773406  ...                         0.034483   \n",
       "4     0.214286  0.274510  0.521031  ...                        -0.344828   \n",
       "...        ...       ...       ...  ...                              ...   \n",
       "5206  0.238095  0.254902  0.660787  ...                         0.068966   \n",
       "5207  0.690476  0.686275  0.750339  ...                        -0.586207   \n",
       "5208  0.428571  0.529412  0.548168  ...                        -0.034483   \n",
       "5209  0.166667  0.117647  1.000000  ...                         0.172414   \n",
       "5210  0.309524  0.333333  0.660787  ...                         0.137931   \n",
       "\n",
       "      OPP_OREB_RANK_opponent_spread  OPP_DREB_RANK_opponent_spread  \\\n",
       "0                         -0.206897                      -0.413793   \n",
       "1                          0.206897                       0.379310   \n",
       "2                          0.206897                       0.413793   \n",
       "3                          0.344828                       0.448276   \n",
       "4                         -0.137931                       0.034483   \n",
       "...                             ...                            ...   \n",
       "5206                      -0.448276                      -1.000000   \n",
       "5207                      -0.448276                      -0.068966   \n",
       "5208                      -0.068966                       0.482759   \n",
       "5209                       0.275862                      -0.034483   \n",
       "5210                      -0.379310                       0.482759   \n",
       "\n",
       "      OPP_REB_RANK_opponent_spread  OPP_AST_RANK_opponent_spread  \\\n",
       "0                        -0.344828                     -0.172414   \n",
       "1                         0.344828                      0.517241   \n",
       "2                         0.344828                      0.172414   \n",
       "3                         0.448276                     -0.241379   \n",
       "4                         0.068966                     -0.103448   \n",
       "...                            ...                           ...   \n",
       "5206                     -1.000000                     -0.758621   \n",
       "5207                     -0.241379                      0.172414   \n",
       "5208                      0.344828                      0.517241   \n",
       "5209                      0.103448                     -0.517241   \n",
       "5210                      0.275862                      0.448276   \n",
       "\n",
       "      OPP_TOV_RANK_opponent_spread  OPP_STL_RANK_opponent_spread  \\\n",
       "0                        -0.413793                     -0.241379   \n",
       "1                        -0.827586                      0.103448   \n",
       "2                         0.413793                      0.241379   \n",
       "3                         0.034483                     -0.517241   \n",
       "4                         0.379310                     -0.482759   \n",
       "...                            ...                           ...   \n",
       "5206                      0.620690                     -0.413793   \n",
       "5207                     -0.724138                     -0.275862   \n",
       "5208                     -0.241379                     -0.517241   \n",
       "5209                      0.034483                      0.103448   \n",
       "5210                      0.241379                      0.413793   \n",
       "\n",
       "      OPP_BLK_RANK_opponent_spread  OPP_PF_RANK_opponent_spread  \\\n",
       "0                         0.379310                    -0.241379   \n",
       "1                        -0.344828                     0.482759   \n",
       "2                        -0.379310                     0.241379   \n",
       "3                        -0.137931                    -0.724138   \n",
       "4                        -0.586207                    -0.448276   \n",
       "...                            ...                          ...   \n",
       "5206                     -0.689655                     0.172414   \n",
       "5207                      0.448276                    -0.379310   \n",
       "5208                      0.379310                    -0.137931   \n",
       "5209                      0.137931                    -0.206897   \n",
       "5210                     -0.344828                    -0.586207   \n",
       "\n",
       "      OPP_PTS_RANK_opponent_spread  \n",
       "0                        -0.379310  \n",
       "1                         0.448276  \n",
       "2                         0.379310  \n",
       "3                        -0.275862  \n",
       "4                        -0.068966  \n",
       "...                            ...  \n",
       "5206                     -0.896552  \n",
       "5207                     -0.379310  \n",
       "5208                      0.103448  \n",
       "5209                      0.482759  \n",
       "5210                      0.517241  \n",
       "\n",
       "[5211 rows x 2474 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings_cols = [i for i in home.columns if 'rank' in i.lower() and 'spread' not in i.lower()]\n",
    "no_rankings = home.columns[~home.columns.isin(rankings_cols)]\n",
    "no_rankings_df = home[no_rankings]\n",
    "no_rankings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce521d0-1717-46c4-8a6d-95b0b34b883c",
   "metadata": {},
   "source": [
    "### Currently Only Training with No Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4dbf8cc2-83b6-4714-99a6-d9b82239dc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "5206    1\n",
       "5207    0\n",
       "5208    0\n",
       "5209    0\n",
       "5210    0\n",
       "Name: target_x, Length: 5211, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = no_rankings_df.select_dtypes(include=['number'])\n",
    "non_numerical_df = no_rankings_df.select_dtypes(exclude=['number'])\n",
    "\n",
    "numerical_df['target_x']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7463db-5621-4bea-8d19-db0360f608c9",
   "metadata": {},
   "source": [
    "## 3. Model Building <a id='3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e5c34-0607-4cbf-824e-a9ba9638520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, model, predictors, true):\n",
    "    X = data[predictors]\n",
    "    y = data['target_x']\n",
    "    \n",
    "    test_size = len(y) // 4\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    fold = 0\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=3, test_size=test_size)\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        f1 = f1_score(y_test, predictions)\n",
    "        accuracy_scores.append(accuracy)\n",
    "    \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_f1 = f1\n",
    "            best_model = model\n",
    "            fold = len(accuracy_scores)\n",
    "\n",
    "        print(f'Accuracy for fold {len(accuracy_scores)}: {accuracy}')\n",
    "        print(f'F1 for fold {len(accuracy_scores)}: {f1}')\n",
    "        print(\"\\n\")\n",
    "\n",
    "    if (True):\n",
    "        count = len(predictors)\n",
    "        accuracy = round(best_accuracy, 3) * 100\n",
    "        save_path = '/Users/liqingyang/Documents/GitHub/sports_trading/sports_betting/ml_notebooks/weights/'\n",
    "        file_path = save_path + f'ridge_with_random_forest_only_spread_{count}_predictors_{accuracy}%_2019_2024.pkl'\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(best_model, f)\n",
    "        \n",
    "        save_path = '/Users/liqingyang/Documents/GitHub/sports_trading/sports_betting/ml_notebooks/factors/'\n",
    "        file_path = save_path + f'predictors_ridge_with_random_forest_only_spread_{count}_predictors_{accuracy}%_2019_2024.txt'\n",
    "        with open(file_path, 'w') as f:\n",
    "            for predictor in predictors:\n",
    "                f.write(f'{predictor},')\n",
    "    \n",
    "        print('-----------------------------------Saved the best model into directory-----------------------------------')\n",
    "        print(f'Best accuracy: {best_accuracy}')\n",
    "        print(f'Best f1 score: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "54aafd18-1ed0-407e-a9ab-9849a387773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_df.loc[:, ~numerical_df.columns.isin(['target_x'])]\n",
    "y = numerical_df['target_x']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675ee43-77c7-4220-a796-a45cc3462fdd",
   "metadata": {},
   "source": [
    "### 3.1 Random Forest Classifier <a id='3_1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e46f6043-9c2e-4596-ad84-501f3308fd96",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# can also try direction backward\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sfs \u001b[38;5;241m=\u001b[39m SequentialFeatureSelector(rf, n_features_to_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m70\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39msplit)\n\u001b[0;32m----> 6\u001b[0m \u001b[43msfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m predictors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(regard[sfs\u001b[38;5;241m.\u001b[39mget_support()])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:246\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    244\u001b[0m is_auto_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 246\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_new_feature_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcloned_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_mask\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_selection/_sequential.py:277\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[1;32m    276\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 277\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    285\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py:372\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m does not match number of samples=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(y), n_samples)\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[43m_check_sample_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDOUBLE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expanded_class_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:1826\u001b[0m, in \u001b[0;36m_check_sample_weight\u001b[0;34m(sample_weight, X, dtype, copy, only_non_negative)\u001b[0m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_sample_weight\u001b[39m(\n\u001b[1;32m   1789\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m ):\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate sample weights.\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m \n\u001b[1;32m   1793\u001b[0m \u001b[38;5;124;03m    Note that passing sample_weight=None will output an array of ones.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;124;03m        Validated sample weight. It is guaranteed to be \"C\" contiguous.\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1826\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m \u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64]:\n\u001b[1;32m   1829\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:339\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(x\u001b[38;5;241m.\u001b[39mfit):\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# Don't get num_samples from an ensembles length!\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__len__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    341\u001b[0m         x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# rf = RandomForestClassifier(n_estimators=350)\n",
    "# split = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# # can also try direction backward\n",
    "# sfs = SequentialFeatureSelector(rf, n_features_to_select = 70, direction='forward', cv=split)\n",
    "# sfs.fit(X, y)\n",
    "# predictors = list(regard[sfs.get_support()])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=350)\n",
    "split = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Using RFE for feature selection instead of SequentialFeatureSelector\n",
    "rfe = RFE(estimator=rf, n_features_to_select=70)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get the support for the features, assuming 'X' is a DataFrame\n",
    "predictors = X.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d199f0-99e2-4bd0-ac2c-a418f5cdefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest(numerical_df, rf, predictors, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934fc83-94e3-40bb-8263-c2486d287d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d0f8458-c0f0-4b88-b58d-ead7af986090",
   "metadata": {},
   "source": [
    "### 3.2 AdaBoost Tree <a id='3_2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf1e60-8442-410e-93a5-1c65eafcb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(n_estimators=100, learning_rate=1.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a46f883-1a61-4554-a928-f6352b230a17",
   "metadata": {},
   "source": [
    "### 3.3 XGBoost (Extreme Gradient Boosting) <a id='3_3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa42314-af34-467c-9f54-84df541f76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, learning_rate=0.1, max_depth=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a11a7-ae79-43ff-8610-750588aab02d",
   "metadata": {},
   "source": [
    "### 3.4 CatBoost Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039e31b-9d85-43da-a671-074f59c6c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostClassifier(iterations=100, learning_rate=1.1, depth=2, loss_function='Logloss', verbose=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
