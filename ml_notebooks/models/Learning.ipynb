{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5548bd",
   "metadata": {},
   "source": [
    "## 1. Import Packages and Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "922a16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "import sklearn.model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "069916da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(team):\n",
    "    team['target'] = team['won'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def rest_days(team):\n",
    "    team['date_time'] = pd.to_datetime(team['date'])\n",
    "    team['rest'] = (team['date_time'] - team['date_time'].shift(1)).dt.days\n",
    "    team['rest'] = team['rest'].fillna(0)\n",
    "    team['rest'] = team['rest'].astype(int)\n",
    "    del team['date_time']\n",
    "    return team\n",
    "\n",
    "def winrate(team):\n",
    "    total = team['Wins'] + team['Losses']\n",
    "    total_opp = team['Wins_opp'] + team['Losses_opp']\n",
    "    team['winrate'] = team['Wins'] / total\n",
    "    team['winrate_opp'] = team['Wins_opp'] / total_opp\n",
    "    return team\n",
    "\n",
    "def differential(team):\n",
    "    team['differential'] = team['Total'] - team['Total_opp']\n",
    "    return team\n",
    "\n",
    "def find_team_exp_average_5(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=5, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_exp_average_9(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=9, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_exp_average_12(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=12, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_15(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(15).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_10(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_5(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(5).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_3(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(3).mean()\n",
    "    return rolling\n",
    "\n",
    "def rolling(data):\n",
    "    df_rolling_3 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_3 = df_rolling_3.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_3)\n",
    "    df_rolling_5 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_5 = df_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_5)\n",
    "    df_rolling_10 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_10 = df_rolling_10.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_10)\n",
    "    df_rolling_15 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_15 = df_rolling_15.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_15)\n",
    "    df_exp_rolling_5 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_5 = df_exp_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_5)\n",
    "    df_exp_rolling_9 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_9 = df_exp_rolling_9.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_9)\n",
    "    df_exp_rolling_12 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_12 = df_exp_rolling_12.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_12)\n",
    "    exp_rolling_columns_5 = [f\"{col}_exp_5\" for col in df_exp_rolling_5.columns]\n",
    "    exp_rolling_columns_9 = [f\"{col}_exp_9\" for col in df_exp_rolling_9.columns]\n",
    "    exp_rolling_columns_12 = [f\"{col}_exp_12\" for col in df_exp_rolling_12.columns]\n",
    "    rolling_columns_15 = [f\"{col}_15\" for col in df_rolling_15.columns]\n",
    "    rolling_columns_10 = [f\"{col}_10\" for col in df_rolling_10.columns]\n",
    "    rolling_columns_5 = [f\"{col}_5\" for col in df_rolling_5.columns]\n",
    "    rolling_columns_3 = [f\"{col}_3\" for col in df_rolling_3.columns]\n",
    "    df_exp_rolling_12.columns = exp_rolling_columns_12\n",
    "    df_exp_rolling_9.columns = exp_rolling_columns_9\n",
    "    df_exp_rolling_5.columns = exp_rolling_columns_5\n",
    "    df_rolling_15.columns = rolling_columns_15\n",
    "    df_rolling_10.columns = rolling_columns_10\n",
    "    df_rolling_5.columns = rolling_columns_5\n",
    "    df_rolling_3.columns = rolling_columns_3\n",
    "    df = pd.concat([data, df_rolling_3, df_rolling_5, df_rolling_10, df_rolling_15, df_exp_rolling_5,df_exp_rolling_9, df_exp_rolling_12], axis=1)\n",
    "    # df_exp_rolling_5,df_exp_rolling_9, df_exp_rolling_12\n",
    "    return df\n",
    "\n",
    "def ratio(feature):\n",
    "    feature_opp = 'OPP_' + str(feature)\n",
    "    free = nba[feature] / nba[feature_opp]\n",
    "    return free\n",
    "\n",
    "def ratios(nba):\n",
    "    regard = []\n",
    "    disregard = [col for col in nba.columns if \"OPP_\" in col]\n",
    "    for col in disregard:\n",
    "        col = col[4:100]\n",
    "        if col in nba.columns:\n",
    "            regard.append(col)\n",
    "    nba_ratio = nba[regard].apply(ratio)\n",
    "    nba_ratios_columns = [f\"{col}_ratio\" for col in nba_ratio.columns]\n",
    "    nba_ratio.columns\n",
    "    return regard\n",
    "\n",
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col\n",
    "\n",
    "def add_col(df, col_name):\n",
    "    return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
    "\n",
    "def date_change(datetime_str):\n",
    "    # Parse the datetime string into a datetime object\n",
    "    datetime_obj = datetime.strptime(datetime_str, '%m/%d/%Y')\n",
    "\n",
    "    # Format the datetime object into a new string structure\n",
    "    new_datetime_str = datetime_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    return new_datetime_str\n",
    "\n",
    "def haircut(df, date):\n",
    "    df[date] = df[date].str[:10]\n",
    "    return df\n",
    "\n",
    "def convert_date_format(df):\n",
    "    # Create a boolean mask to identify values in the \"m/d/y\" format\n",
    "    mask = df['Date'].str.contains(r'\\d{1,2}/\\d{1,2}/\\d{2}')\n",
    "    \n",
    "    # Apply the conversion only to values that match the mask\n",
    "    df.loc[mask, 'Date'] = nba.loc[mask, 'Date'].apply(date_change)\n",
    "    return df\n",
    "\n",
    "def spread(df):\n",
    "    # construct spread between home and away rankings\n",
    "    ranks = [i for i in df.columns if 'RANK' in i]\n",
    "    ranks_home = [i for i in ranks if '_x' in i]\n",
    "    ranks_away = [i for i in ranks if '_y' in i]\n",
    "    spread_columns_names = [col[:-1] for col in ranks_home]\n",
    "    \n",
    "    spread_columns = []\n",
    "    for base_name in spread_columns_names:\n",
    "        spread_column = df[f'{base_name}x'] - df[f'{base_name}y']\n",
    "        spread_column.name = f'{base_name}spread'\n",
    "        spread_columns.append(spread_column)\n",
    "        \n",
    "    spread_df = pd.concat(spread_columns, axis=1)\n",
    "    return spread_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d6afb006",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/benjamincheng/Documents/GitHub/Sports-Betting/data/raw_data/NBA_2018_2024.csv\"\n",
    "df = pd.read_csv(folder_path, index_col=0)\n",
    "\n",
    "folder_path = \"/Users/benjamincheng/Documents/GitHub/Sports-Betting/nba_api/data/teams_stats/processed_cumulative_season_stats_2019_2024.csv\"\n",
    "nba = pd.read_csv(folder_path, index_col=0)\n",
    "\n",
    "folder_path = \"/Users/benjamincheng/Documents/GitHub/Sports-Betting/data/odds_data/2021_01_20_onward.csv\"\n",
    "odds = pd.read_csv(folder_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8fcc6",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling and Preprocessing for Modeling\n",
    "- In this code, I have scaled the ranking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7c7c2067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/833364530.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"Teams\", group_keys=False).apply(add_target)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/833364530.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby([\"Teams\",'season'], group_keys=False).apply(rest_days)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling_3 = df_rolling_3.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_3)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling_5 = df_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_5)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:65: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling_10 = df_rolling_10.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_10)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling_15 = df_rolling_15.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_15)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:69: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_exp_rolling_5 = df_exp_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_5)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:71: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_exp_rolling_9 = df_exp_rolling_9.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_9)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:73: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_exp_rolling_12 = df_exp_rolling_12.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_12)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:114: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:114: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/2295180556.py:114: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n"
     ]
    }
   ],
   "source": [
    "# nba dataframe does not include the 2018 season\n",
    "df = df[~df['season'].isin([2018])]\n",
    "df = df.reset_index(drop=True)\n",
    "df = haircut(df, 'date')\n",
    "\n",
    "# rename nba columns to match df\n",
    "nba = haircut(nba, 'Date')\n",
    "nba = convert_date_format(nba)\n",
    "nba.rename(columns={'Date': 'date'}, inplace=True)\n",
    "\n",
    "#rename odds columns to match df\n",
    "odds.rename(columns={'Timestamp': 'date_next'}, inplace=True)\n",
    "\n",
    "# construct winrate for team\n",
    "df = winrate(df)\n",
    "# construct differential points\n",
    "df = differential(df)\n",
    "# construct target\n",
    "df = df.groupby(\"Teams\", group_keys=False).apply(add_target)\n",
    "# construct resting\n",
    "df = df.groupby([\"Teams\",'season'], group_keys=False).apply(rest_days)\n",
    "# games yet to play are 2\n",
    "df.loc[pd.isnull(df['target']), 'target'] = 2\n",
    "# convert win/loss to 1/0\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "# remove metadata and target for df\n",
    "removed = ['target', 'date', 'Teams_opp', 'Teams',\n",
    "           'season','won', 'Wins', 'Losses', \n",
    "           'Wins_opp', 'Losses_opp']\n",
    "valid_columns = df.columns[~df.columns.isin(removed)]\n",
    "\n",
    "# scale the data for df\n",
    "scaler = MinMaxScaler()\n",
    "df[valid_columns] = scaler.fit_transform(df[valid_columns])\n",
    "\n",
    "# construct rolling features to df\n",
    "df = rolling(df).copy()\n",
    "df = df.dropna()\n",
    "\n",
    "# remove metadata for nba ranking \n",
    "removed = ['date', 'Teams']\n",
    "valid_columns = nba.columns[~nba.columns.isin(removed)]\n",
    "\n",
    "# scale the ranking data\n",
    "scaler = MinMaxScaler()\n",
    "nba[valid_columns] = scaler.fit_transform(nba[valid_columns])\n",
    "\n",
    "# remove metadata for odds data\n",
    "# removed = list(odds.columns[odds.dtypes == 'object'])\n",
    "# valid_columns = odds.columns[~nba.columns.isin(removed)]\n",
    "\n",
    "# scale the odds data\n",
    "# scaler = MinMaxScaler()\n",
    "# odds[valid_columns] = scaler.fit_transform(odds[valid_columns])\n",
    "\n",
    "# construct current game metadata for df\n",
    "df['home_next'] = add_col(df, 'home')\n",
    "df['team_next_opp'] = add_col(df, 'Teams_opp')\n",
    "df['date_next'] = add_col(df, 'date')\n",
    "df = df.copy()\n",
    "\n",
    "# merge stats from nba dataframe\n",
    "full = pd.merge(df, nba, on=['Teams', 'date'], how='left')\n",
    "full = full.dropna()\n",
    "\n",
    "# merge stats from opposing teams\n",
    "complete = full.merge(full,\n",
    "               left_on=['Teams', 'date_next'],\n",
    "               right_on = ['team_next_opp', 'date_next'])\n",
    "\n",
    "# concat the spreads\n",
    "spread_df = spread(complete)\n",
    "complete = pd.concat([complete, spread_df], axis=1)\n",
    "\n",
    "# concat the odds\n",
    "complete = pd.merge(complete, odds, on=['Teams_x', 'date_next', 'Teams_y'], how='left')\n",
    "complete = complete.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "275165af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_17137/1489752924.py:5: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  complete_cleaning[column] = pd.to_numeric(complete_cleaning[column], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "complete_cleaning = complete.copy()\n",
    "# Dropping duplicated columns\n",
    "complete_cleaning = complete_cleaning.T.drop_duplicates(keep='first').T\n",
    "for column in complete_cleaning.columns:\n",
    "    complete_cleaning[column] = pd.to_numeric(complete_cleaning[column], errors='ignore')\n",
    "# remove metadata and useless data\n",
    "disregard = list(complete_cleaning.columns[complete_cleaning.dtypes == 'object']) \n",
    "disregard = disregard + [\"target_x\",\"target_y\"]\n",
    "regard = complete_cleaning.columns[~complete_cleaning.columns.isin(disregard)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e3a7fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/Users/benjamincheng/Documents/GitHub/Sports-Betting/data/processed_data/'\n",
    "file = 'cleaned_2019_2024_71.8%_odds.csv'\n",
    "file_name = save_path + file\n",
    "complete_cleaning.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "eed3e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to exclude January 2024 - March 2024 data from dataframe to use for out of sample testing\n",
    "complete_cleaning = complete_cleaning[~complete_cleaning['date_next'].str.contains('2024-03')|complete_cleaning['date_next'].str.contains('2024-02')|complete_cleaning['date_next'].str.contains('2024-01')]\n",
    "complete_cleaning = complete_cleaning.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e53f93",
   "metadata": {},
   "source": [
    "## 3. Modeling without Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a29dcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "rr = RidgeClassifier(alpha=1)\n",
    "split = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# can also try direction backward\n",
    "sfs = SequentialFeatureSelector(rr, n_features_to_select = 85, direction='forward', cv=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c52fb0fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[274], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomplete_cleaning\u001b[49m\u001b[43m[\u001b[49m\u001b[43mregard\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplete_cleaning\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/feature_selection/_sequential.py:246\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    244\u001b[0m is_auto_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 246\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_new_feature_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcloned_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_mask\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/feature_selection/_sequential.py:277\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[1;32m    276\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 277\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    285\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1446\u001b[0m, in \u001b[0;36mRidgeClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Ridge classifier model.\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \n\u001b[1;32m   1424\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;124;03m    Instance of the estimator.\u001b[39;00m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1444\u001b[0m X, y, sample_weight, Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_data(X, y, sample_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver)\n\u001b[0;32m-> 1446\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:894\u001b[0m, in \u001b[0;36m_BaseRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m         \u001b[38;5;66;03m# for dense matrices or when intercept is set to 0\u001b[39;00m\n\u001b[1;32m    892\u001b[0m         params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 894\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_ridge_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_intercept(X_offset, y_offset, X_scale)\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:704\u001b[0m, in \u001b[0;36m_ridge_regression\u001b[0;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, positive, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input, fit_intercept)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         coef \u001b[38;5;241m=\u001b[39m \u001b[43m_solve_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;66;03m# use SVD solver if matrix is singular\u001b[39;00m\n\u001b[1;32m    707\u001b[0m         solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:205\u001b[0m, in \u001b[0;36m_solve_cholesky\u001b[0;34m(X, y, alpha)\u001b[0m\n\u001b[1;32m    202\u001b[0m n_targets \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    204\u001b[0m A \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X\u001b[38;5;241m.\u001b[39mT, X, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 205\u001b[0m Xy \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m one_alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_equal(alpha, \u001b[38;5;28mlen\u001b[39m(alpha) \u001b[38;5;241m*\u001b[39m [alpha[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m one_alpha:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/extmath.py:196\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 196\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m ):\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/scipy/sparse/_base.py:1461\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[0;32m-> 1461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array type?\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \n\u001b[1;32m   1464\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sfs.fit(complete_cleaning[regard], complete_cleaning['target_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b65944",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(regard[sfs.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349879f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "342e37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "import pickle \n",
    "\n",
    "def backtest(data, model, predictors, true):\n",
    "    X = data[predictors]\n",
    "    y = data['target_x']\n",
    "    \n",
    "    test_size = len(y) // 4\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    fold = 0\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=3, test_size=test_size)\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        f1 = f1_score(y_test, predictions)\n",
    "        accuracy_scores.append(accuracy)\n",
    "    \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_f1 = f1\n",
    "            best_model = model\n",
    "            fold = len(accuracy_scores)\n",
    "\n",
    "        print(f'Accuracy for fold {len(accuracy_scores)}: {accuracy}')\n",
    "        print(f'F1 for fold {len(accuracy_scores)}: {f1}')\n",
    "        print(\"\\n\")\n",
    "\n",
    "    if (True):\n",
    "        count = len(predictors)\n",
    "        accuracy = round(best_accuracy * 100, 1) \n",
    "        save_path = '/Users/benjamincheng/Documents/GitHub/Sports-Betting/ml_notebooks/weights/'\n",
    "        file_path = save_path + f'ridge_classifier_{count}_predictors_{accuracy}%_2019_2024.pkl'\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(best_model, f)\n",
    "        \n",
    "        save_path = '/Users/benjamincheng/Documents/GitHub/Sports-Betting/ml_notebooks/factors/'\n",
    "        file_path = save_path + f'predictors_ridge_classifier_{count}_predictors_{accuracy}%_2019_2024.txt'\n",
    "        with open(file_path, 'w') as f:\n",
    "            for predictor in predictors:\n",
    "                f.write(f'{predictor},')\n",
    "    \n",
    "        print('-----------------------------------Saved the best model into directory-----------------------------------')\n",
    "        print(f'Best accuracy: {best_accuracy}')\n",
    "        print(f'Best f1 score: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "716e13fd",
<<<<<<< HEAD
   "metadata": {
    "scrolled": false
   },
=======
   "metadata": {},
>>>>>>> c6d6545391b3690a66c97fa247b02e740ca682a9
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1: 0.7068461088355764\n",
      "F1 for fold 1: 0.7030231179608772\n",
      "\n",
      "\n",
      "Accuracy for fold 2: 0.6775892334698654\n",
      "F1 for fold 2: 0.6787172011661807\n",
      "\n",
      "\n",
      "Accuracy for fold 3: 0.7179637214745466\n",
      "F1 for fold 3: 0.7174677608440797\n",
      "\n",
      "\n",
      "-----------------------------------Saved the best model into directory-----------------------------------\n",
      "Best accuracy: 0.7179637214745466\n",
      "Best f1 score: 0.7174677608440797\n"
     ]
    }
   ],
   "source": [
    "backtest(complete_cleaning, rr, predictors, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4f34fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this backtest will take in odds data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde1f139",
   "metadata": {},
   "source": [
    "## 4. Modeling with Split\n",
    "We noticed that we are training a model with the same data twice over. We are going to try to apply a list comprehension to form a dataset of home teams in x and away teams in y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09fa05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete is dataframe with both ranking and stats \n",
    "home = complete[complete['home_x'] == 1]\n",
    "home = home.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d358c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "rr = RidgeClassifier(alpha=1)\n",
    "split = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# can also try direction backward\n",
    "sfs = SequentialFeatureSelector(rr, n_features_to_select = 70, direction='forward', cv=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5cf2599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=RidgeClassifier(alpha=1),\n",
       "                          n_features_to_select=70)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=RidgeClassifier(alpha=1),\n",
       "                          n_features_to_select=70)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=RidgeClassifier(alpha=1),\n",
       "                          n_features_to_select=70)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.fit(home[regard], home['target_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f4a13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(regard[sfs.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef409ab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['usg%_x',\n",
       " 'ft%maxes_x',\n",
       " 'astmaxes_x',\n",
       " 'home_x',\n",
       " 'ast%_opp_x',\n",
       " 'usg%_opp_x',\n",
       " 'home_opp_x',\n",
       " 'winrate_x',\n",
       " 'mp_3_x',\n",
       " 'usg%_3_x',\n",
       " 'efg%maxes_3_x',\n",
       " 'usg%_opp_3_x',\n",
       " 'blk%maxes_opp_3_x',\n",
       " 'winrate_3_x',\n",
       " 'usg%_5_x',\n",
       " 'efg%maxes_5_x',\n",
       " 'usg%_opp_5_x',\n",
       " 'winrate_5_x',\n",
       " 'differential_5_x',\n",
       " 'blk_10_x',\n",
       " 'usg%_10_x',\n",
       " 'usg%_opp_10_x',\n",
       " 'ft%maxes_opp_10_x',\n",
       " 'trb%maxes_opp_10_x',\n",
       " 'usg%_15_x',\n",
       " 'ts%maxes_15_x',\n",
       " 'stl%maxes_15_x',\n",
       " 'usg%_opp_15_x',\n",
       " 'usg%_exp_5_x',\n",
       " 'usg%_opp_exp_5_x',\n",
       " 'usg%_exp_9_x',\n",
       " 'fgmaxes_exp_9_x',\n",
       " 'tov%maxes_exp_9_x',\n",
       " 'usg%_opp_exp_9_x',\n",
       " 'mp_exp_12_x',\n",
       " 'usg%_exp_12_x',\n",
       " 'fgmaxes_exp_12_x',\n",
       " 'usg%_opp_exp_12_x',\n",
       " 'home_next_x',\n",
       " 'usg%_y',\n",
       " '+/-maxes_y',\n",
       " 'usg%_opp_y',\n",
       " 'ft%maxes_opp_y',\n",
       " 'usg%_3_y',\n",
       " 'fgmaxes_3_y',\n",
       " 'usg%_opp_3_y',\n",
       " 'stl%maxes_opp_3_y',\n",
       " 'usg%_5_y',\n",
       " 'blk_opp_5_y',\n",
       " 'usg%_opp_5_y',\n",
       " 'usg%_10_y',\n",
       " '+/-maxes_10_y',\n",
       " 'usg%_opp_10_y',\n",
       " 'usg%_15_y',\n",
       " 'usg%_opp_15_y',\n",
       " 'stl%maxes_opp_15_y',\n",
       " 'usg%_exp_5_y',\n",
       " '3pamaxes_exp_5_y',\n",
       " 'usg%_opp_exp_5_y',\n",
       " 'astmaxes_opp_exp_5_y',\n",
       " 'usg%_exp_9_y',\n",
       " 'trbmaxes_exp_9_y',\n",
       " 'usg%_opp_exp_9_y',\n",
       " 'usg%_exp_12_y',\n",
       " 'usg%_opp_exp_12_y',\n",
       " 'home_next_y',\n",
       " 'W_PCT_base',\n",
       " 'E_NET_RATING_advanced',\n",
       " 'W_PCT_RANK_misc',\n",
       " 'OPP_FG3_PCT_RANK_opponent']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55b34d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold 1: 0.7893927747886241\n",
      "F1 for fold 1: 0.7958271236959761\n",
      "\n",
      "\n",
      "Accuracy for fold 2: 0.813989239046887\n",
      "F1 for fold 2: 0.8199404761904762\n",
      "\n",
      "\n",
      "Accuracy for fold 3: 0.8401229823212913\n",
      "F1 for fold 3: 0.8501440922190201\n",
      "\n",
      "\n",
      "-----------------------------------Saved the best model into directory-----------------------------------\n",
      "Best accuracy: 0.8401229823212913\n",
      "Best f1 score: 0.8501440922190201\n"
     ]
    }
   ],
   "source": [
    "backtest(home, rr, predictors, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
