{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5548bd",
   "metadata": {},
   "source": [
    "## 1. Import Packages and Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "922a16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "import sklearn.model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069916da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(team):\n",
    "    team['target'] = team['won'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def winrate(team):\n",
    "    total = team['Wins'] + team['Losses']\n",
    "    total_opp = team['Wins_opp'] + team['Losses_opp']\n",
    "    team['winrate'] = team['Wins'] / total\n",
    "    team['winrate_opp'] = team['Wins_opp'] / total_opp\n",
    "    return team\n",
    "\n",
    "def differential(team):\n",
    "    team['differential'] = team['Total'] - team['Total_opp']\n",
    "    return team\n",
    "\n",
    "def find_team_exp_average_5(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=5, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_exp_average_9(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=9, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_exp_average_12(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=12, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_15(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(15).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_10(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_5(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(5).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_3(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(3).mean()\n",
    "    return rolling\n",
    "\n",
    "def rolling(data):\n",
    "    df_rolling_3 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_3 = df_rolling_3.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_3)\n",
    "    df_rolling_5 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_5 = df_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_5)\n",
    "    df_rolling_10 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_10 = df_rolling_10.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_10)\n",
    "    df_rolling_15 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_15 = df_rolling_15.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_15)\n",
    "    df_exp_rolling_5 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_5 = df_exp_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_5)\n",
    "    df_exp_rolling_9 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_9 = df_exp_rolling_9.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_9)\n",
    "    df_exp_rolling_12 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_12 = df_exp_rolling_12.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_12, include_groups=False)\n",
    "    exp_rolling_columns_5 = [f\"{col}_exp_5\" for col in df_exp_rolling_5.columns]\n",
    "    exp_rolling_columns_9 = [f\"{col}_exp_9\" for col in df_exp_rolling_9.columns]\n",
    "    exp_rolling_columns_12 = [f\"{col}_exp_12\" for col in df_exp_rolling_12.columns]\n",
    "    rolling_columns_15 = [f\"{col}_15\" for col in df_rolling_15.columns]\n",
    "    rolling_columns_10 = [f\"{col}_10\" for col in df_rolling_10.columns]\n",
    "    rolling_columns_5 = [f\"{col}_5\" for col in df_rolling_5.columns]\n",
    "    rolling_columns_3 = [f\"{col}_3\" for col in df_rolling_3.columns]\n",
    "    df_exp_rolling_12.columns = exp_rolling_columns_12\n",
    "    df_exp_rolling_9.columns = exp_rolling_columns_9\n",
    "    df_exp_rolling_5.columns = exp_rolling_columns_5\n",
    "    df_rolling_15.columns = rolling_columns_15\n",
    "    df_rolling_10.columns = rolling_columns_10\n",
    "    df_rolling_5.columns = rolling_columns_5\n",
    "    df_rolling_3.columns = rolling_columns_3\n",
    "    df = pd.concat([data, df_rolling_3, df_rolling_5, df_rolling_10, df_rolling_15,df_exp_rolling_5,df_exp_rolling_9, df_exp_rolling_12], axis=1)\n",
    "    return df\n",
    "\n",
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col\n",
    "\n",
    "def add_col(df, col_name):\n",
    "    return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
    "\n",
    "def date_change(datetime_str):\n",
    "    # Parse the datetime string into a datetime object\n",
    "    datetime_obj = datetime.strptime(datetime_str, '%m/%d/%Y')\n",
    "\n",
    "    # Format the datetime object into a new string structure\n",
    "    new_datetime_str = datetime_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    return new_datetime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6afb006",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/benjamincheng/Documents/GitHub/Sports-Betting/data/raw_data/NBA_2018_2024.csv\"\n",
    "df = pd.read_csv(folder_path, index_col=0)\n",
    "\n",
    "folder_path = \"/Users/benjamincheng/Documents/GitHub/Sports-Betting/nba_api/data/teams_stats/processed_cumulative_season_stats_2019_2024.csv\"\n",
    "nba = pd.read_csv(folder_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8fcc6",
   "metadata": {},
   "source": [
    "### 2. Data Wrangling and Preprocessing for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c7c2067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/2962729090.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"Teams\", group_keys=False).apply(add_target)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/1514409352.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling_3 = df_rolling_3.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_3)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/1514409352.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling_5 = df_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_5)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/1514409352.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling_10 = df_rolling_10.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_10)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/1514409352.py:59: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_rolling_15 = df_rolling_15.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_15)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/1514409352.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_exp_rolling_5 = df_exp_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_5)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/1514409352.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_exp_rolling_9 = df_exp_rolling_9.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_9)\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/1514409352.py:88: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/1514409352.py:88: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
      "/var/folders/99/zv3w4flx1598dxlknc099kfr0000gn/T/ipykernel_6626/1514409352.py:88: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n"
     ]
    }
   ],
   "source": [
    "# nba dataframe does not include the 2018 season\n",
    "df = df[~df['season'].isin([2018])]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# rename nba columns to match df\n",
    "nba.rename(columns={'Date': 'date_next', 'Teams':'Teams_x'}, inplace=True)\n",
    "\n",
    "# construct winrate for team\n",
    "df = winrate(df)\n",
    "# construct differential points\n",
    "df = differential(df)\n",
    "# construct target\n",
    "df = df.groupby(\"Teams\", group_keys=False).apply(add_target)\n",
    "\n",
    "# games yet to play are 2\n",
    "df.loc[pd.isnull(df['target']), 'target'] = 2\n",
    "# convert win/loss to 1/0\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "# remove metadata and target\n",
    "removed = ['target', 'date', 'Teams_opp', 'Teams',\n",
    "           'season','won', 'Wins', 'Losses', \n",
    "           'Wins_opp', 'Losses_opp']\n",
    "valid_columns = df.columns[~df.columns.isin(removed)]\n",
    "\n",
    "# scale the data\n",
    "scaler = MinMaxScaler()\n",
    "df[valid_columns] = scaler.fit_transform(df[valid_columns])\n",
    "\n",
    "# construct rolling features to df\n",
    "df = rolling(df).copy()\n",
    "df = df.dropna()\n",
    "\n",
    "# construct current game metadata\n",
    "df['home_next'] = add_col(df, 'home')\n",
    "df['team_next_opp'] = add_col(df, 'Teams_opp')\n",
    "df['date_next'] = add_col(df, 'date')\n",
    "df = df.copy()\n",
    "\n",
    "# merge stats from opposing teams\n",
    "full = df.merge(df,\n",
    "               left_on=['Teams', 'date_next'],\n",
    "               right_on = ['team_next_opp', 'date_next'])\n",
    "\n",
    "# merge stats from nba dataframe\n",
    "full = pd.merge(full, nba, on=['Teams_x', 'date_next'], how='left')\n",
    "full = full.dropna()\n",
    "\n",
    "# remove metadata and useless data\n",
    "disregard = list(full.columns[full.dtypes == 'object']) \n",
    "disregard = disregard + [\"home_opp_5_x\",\"target_x\",\"target_y\", \n",
    "                         \"Wins_x\", \"Losses_x\", \"Wins_opp_x\", \n",
    "                         \"Losses_opp_x\", \"season_x\" , \"won_x\" , \n",
    "                         \"home_5_x\" ,\"home_10_x\" ,\"season_5_x\", \n",
    "                         \"season_10_x\" , \"Wins_y\" , \"Losses_y\" , \n",
    "                         \"Wins_opp_y\" , \"Losses_opp_y\" , \"season_y\" , \n",
    "                         \"won_y\" ,\"home_5_y\", \"home_10_y\",\"season_5_y\", \n",
    "                         \"season_10_y\",\"home_opp_5_y\", \"home_opp_10_y\"]\n",
    "regard = full.columns[~full.columns.isin(disregard)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6818d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed dataframe\n",
    "save_path = '/Users/benjamincheng/Documents/GitHub/Sports-Betting/data/processed_data/'\n",
    "file = 'processed_2019_2024.csv'\n",
    "file_name = save_path + file\n",
    "full.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e53f93",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a29dcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "rr = RidgeClassifier(alpha=1)\n",
    "split = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# can also try direction backward\n",
    "sfs = SequentialFeatureSelector(rr, n_features_to_select = 70, direction='forward', cv=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c52fb0fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=RidgeClassifier(alpha=1),\n",
       "                          n_features_to_select=70)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=RidgeClassifier(alpha=1),\n",
       "                          n_features_to_select=70)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier(alpha=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                          estimator=RidgeClassifier(alpha=1),\n",
       "                          n_features_to_select=70)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.fit(full[regard], full['target_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16b65944",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(regard[sfs.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "349879f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efg%_x',\n",
       " 'usg%_x',\n",
       " 'eFG%_x',\n",
       " 'usg%_opp_x',\n",
       " 'winrate_x',\n",
       " 'tov_3_x',\n",
       " 'usg%_3_x',\n",
       " 'usg%_opp_3_x',\n",
       " 'tov%maxes_opp_3_x',\n",
       " 'winrate_3_x',\n",
       " 'usg%_5_x',\n",
       " 'usg%_opp_5_x',\n",
       " 'fga_10_x',\n",
       " 'usg%_10_x',\n",
       " 'ortg_10_x',\n",
       " 'drtg_10_x',\n",
       " '3pamaxes_10_x',\n",
       " 'drtgmaxes_10_x',\n",
       " 'ORtg_10_x',\n",
       " '3pa_opp_10_x',\n",
       " 'usg%_opp_10_x',\n",
       " 'ortg_opp_10_x',\n",
       " 'drtg_opp_10_x',\n",
       " 'differential_10_x',\n",
       " 'tov_15_x',\n",
       " 'usg%_15_x',\n",
       " 'usg%_opp_15_x',\n",
       " '3p%maxes_opp_15_x',\n",
       " 'tov_exp_5_x',\n",
       " 'ast%_exp_5_x',\n",
       " 'usg%_exp_5_x',\n",
       " 'stl%maxes_exp_5_x',\n",
       " 'usg%_opp_exp_5_x',\n",
       " 'winrate_exp_5_x',\n",
       " 'usg%_exp_9_x',\n",
       " 'ts%_opp_exp_9_x',\n",
       " 'usg%_opp_exp_9_x',\n",
       " '+/-maxes_opp_exp_9_x',\n",
       " 'usg%_exp_12_x',\n",
       " '3pa_opp_exp_12_x',\n",
       " 'usg%_opp_exp_12_x',\n",
       " '3pamaxes_opp_exp_12_x',\n",
       " 'usg%_y',\n",
       " 'usg%_opp_y',\n",
       " 'usg%_3_y',\n",
       " 'usg%_opp_3_y',\n",
       " 'usg%_5_y',\n",
       " 'usg%_opp_5_y',\n",
       " 'usg%_10_y',\n",
       " 'usg%_opp_10_y',\n",
       " 'stl%maxes_opp_10_y',\n",
       " 'usg%_15_y',\n",
       " 'usg%_opp_15_y',\n",
       " 'stl%maxes_opp_15_y',\n",
       " 'usg%_exp_5_y',\n",
       " 'usg%_opp_exp_5_y',\n",
       " 'usg%_exp_9_y',\n",
       " 'stl%_opp_exp_9_y',\n",
       " 'usg%_opp_exp_9_y',\n",
       " 'stl%maxes_opp_exp_9_y',\n",
       " 'usg%_exp_12_y',\n",
       " 'usg%_opp_exp_12_y',\n",
       " 'stl%maxes_opp_exp_12_y',\n",
       " 'W_PCT_base',\n",
       " 'W_PCT_RANK_base',\n",
       " 'E_NET_RATING_advanced',\n",
       " 'REB_PCT_advanced',\n",
       " 'NET_RATING_RANK_advanced',\n",
       " 'OPP_PTS_FB_RANK_misc',\n",
       " 'OPP_FT_PCT_opponent']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "342e37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "import pickle \n",
    "\n",
    "def backtest(data, model, predictors, true):\n",
    "    X = data[predictors]\n",
    "    y = data['target_x']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.20, random_state=42)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    result = pd.Series(predictions, index = y_test.index)\n",
    "    \n",
    "    final = pd.concat([y_test, result], axis=1)\n",
    "    final.columns = ['Actual', 'Predictions']\n",
    "    if (True):\n",
    "        with open('70_87.3%_ridge_classifier_2019-2024.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "    print(model.coef_)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "716e13fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.62641137e-01  0.00000000e+00 -1.62641137e-01  0.00000000e+00\n",
      "  -9.62305732e+00  1.74947981e-01  0.00000000e+00  0.00000000e+00\n",
      "  -8.62025456e-03 -4.55184334e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.55051862e-01  0.00000000e+00  3.88640686e-02 -3.31291176e-01\n",
      "   6.00263675e-02  4.29007434e-01  3.88640686e-02  2.27879600e-01\n",
      "   0.00000000e+00 -3.31291176e-01  3.88640686e-02  1.27507706e-01\n",
      "  -5.52326079e-01  0.00000000e+00  0.00000000e+00  1.10658538e-01\n",
      "   2.20684009e-01  6.30930866e-03  0.00000000e+00  7.96480812e-01\n",
      "   0.00000000e+00 -3.87215967e+00  0.00000000e+00  6.20079359e-01\n",
      "   0.00000000e+00  1.11541847e+00  0.00000000e+00 -3.10677707e-01\n",
      "   0.00000000e+00 -2.29087179e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.37408096e-01  0.00000000e+00\n",
      "   0.00000000e+00 -1.00269910e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  8.58078342e-01  0.00000000e+00 -2.18016405e-01\n",
      "   0.00000000e+00  0.00000000e+00 -6.77696624e-02  1.65586091e+01\n",
      "  -4.25370832e-02  5.57213557e-02  4.85386989e-01  1.04509424e-02\n",
      "  -1.70842273e-03 -2.25643972e-01]]\n"
     ]
    }
   ],
   "source": [
    "final = backtest(full, rr, predictors, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74497766",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7352</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10669</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10670</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10671</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10673</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1838 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predictions\n",
       "7348        1            1\n",
       "7349        1            1\n",
       "7350        0            0\n",
       "7351        0            0\n",
       "7352        0            0\n",
       "...       ...          ...\n",
       "10669       1            1\n",
       "10670       1            1\n",
       "10671       1            1\n",
       "10672       0            0\n",
       "10673       0            0\n",
       "\n",
       "[1838 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf97075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(final['Actual'], final['Predictions'])\n",
    "f1 = f1_score(final['Actual'], final['Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "690724b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  0.8541893362350381\n",
      "The f1 is:  0.8559139784946237\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy is: \", accuracy)\n",
    "print(\"The f1 is: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb584704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictors \n",
    "# file_path = 'Predictions/Factors/70_87.3%_predictors_ridge_classifier_2019-2024.txt'\n",
    "# with open(file_path, 'w') as f:\n",
    "#     for predictor in predictors:\n",
    "#         f.write(f'{predictor},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1da417ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_time_series(data, model, predictors, true):\n",
    "    X = data[predictors]\n",
    "    y = data['target_x']\n",
    "    \n",
    "    test_size = len(y) // 4\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=3, test_size=test_size)\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        result = pd.Series(predictions, index=y_test.index)\n",
    "        \n",
    "        final = pd.concat([y_test, result], axis=1)\n",
    "        final.columns = ['Actual', 'Predictions']\n",
    "        \n",
    "        \n",
    "    if (True):\n",
    "        with open('time_series_ridge_classifier_2018-2024.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd850a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time_series = backtest_time_series(full, rr, predictors, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fee28c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_time = accuracy_score(final_time_series['Actual'], final_time_series['Predictions'])\n",
    "f1_time = f1_score(final_time_series['Actual'], final_time_series['Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad8a31ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  0.850609756097561\n",
      "The f1 is:  0.8533561351004704\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy is: \", accuracy_time)\n",
    "print(\"The f1 is: \", f1_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
