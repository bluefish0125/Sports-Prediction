{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645ed76a-94c1-42a8-8163-86a007822ed7",
   "metadata": {},
   "source": [
    "- [1. Import Packages and Dataset](#1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad23ea1-bbd4-4bc3-8c47-a800aa227cf3",
   "metadata": {},
   "source": [
    "## 1. Import Packages and Dataset <a id='1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdde3890-2c94-4bff-b59f-e67a858436ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import desired packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import statsmodels.api as sm\n",
    "import gc\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, TimeSeriesSplit, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, RidgeClassifier, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, silhouette_score, f1_score, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, SequentialFeatureSelector, RFE\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "331d7021-555b-416a-b5fe-54ce6668687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "# import torch.nn as nn\n",
    "# import sklearn.model_selection\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "def add_target(team):\n",
    "    team['target'] = team['won'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def winrate(team):\n",
    "    total = team['Wins'] + team['Losses']\n",
    "    total_opp = team['Wins_opp'] + team['Losses_opp']\n",
    "    team['winrate'] = team['Wins'] / total\n",
    "    team['winrate_opp'] = team['Wins_opp'] / total_opp\n",
    "    return team\n",
    "\n",
    "def differential(team):\n",
    "    team['differential'] = team['Total'] - team['Total_opp']\n",
    "    return team\n",
    "\n",
    "def find_team_exp_average_5(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=5, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_exp_average_9(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=9, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_exp_average_12(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.ewm(span=12, adjust=False).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_15(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(15).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_10(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_5(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(5).mean()\n",
    "    return rolling\n",
    "\n",
    "def find_team_average_3(team):\n",
    "    numeric_columns = team.select_dtypes(include=np.number)\n",
    "    rolling = numeric_columns.rolling(3).mean()\n",
    "    return rolling\n",
    "\n",
    "def rolling(data):\n",
    "    df_rolling_3 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_3 = df_rolling_3.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_3)\n",
    "    df_rolling_5 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_5 = df_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_5)\n",
    "    df_rolling_10 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_10 = df_rolling_10.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_10)\n",
    "    df_rolling_15 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_rolling_15 = df_rolling_15.groupby(['Teams', 'season'], group_keys = False).apply(find_team_average_15)\n",
    "    df_exp_rolling_5 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_5 = df_exp_rolling_5.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_5)\n",
    "    df_exp_rolling_9 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_9 = df_exp_rolling_9.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_9)\n",
    "    df_exp_rolling_12 = data[list(valid_columns) + ['Teams','won', \"season\"]]\n",
    "    df_exp_rolling_12 = df_exp_rolling_12.groupby(['Teams', 'season'], group_keys = False).apply(find_team_exp_average_12, include_groups=False)\n",
    "    exp_rolling_columns_5 = [f\"{col}_exp_5\" for col in df_exp_rolling_5.columns]\n",
    "    exp_rolling_columns_9 = [f\"{col}_exp_9\" for col in df_exp_rolling_9.columns]\n",
    "    exp_rolling_columns_12 = [f\"{col}_exp_12\" for col in df_exp_rolling_12.columns]\n",
    "    rolling_columns_15 = [f\"{col}_15\" for col in df_rolling_15.columns]\n",
    "    rolling_columns_10 = [f\"{col}_10\" for col in df_rolling_10.columns]\n",
    "    rolling_columns_5 = [f\"{col}_5\" for col in df_rolling_5.columns]\n",
    "    rolling_columns_3 = [f\"{col}_3\" for col in df_rolling_3.columns]\n",
    "    df_exp_rolling_12.columns = exp_rolling_columns_12\n",
    "    df_exp_rolling_9.columns = exp_rolling_columns_9\n",
    "    df_exp_rolling_5.columns = exp_rolling_columns_5\n",
    "    df_rolling_15.columns = rolling_columns_15\n",
    "    df_rolling_10.columns = rolling_columns_10\n",
    "    df_rolling_5.columns = rolling_columns_5\n",
    "    df_rolling_3.columns = rolling_columns_3\n",
    "    df = pd.concat([data, df_rolling_3, df_rolling_5, df_rolling_10, df_rolling_15,df_exp_rolling_5,df_exp_rolling_9, df_exp_rolling_12], axis=1)\n",
    "    return df\n",
    "\n",
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col\n",
    "\n",
    "def add_col(df, col_name):\n",
    "    return df.groupby(\"Teams\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
    "\n",
    "def date_change(datetime_str):\n",
    "    # Parse the datetime string into a datetime object\n",
    "    datetime_obj = datetime.strptime(datetime_str, '%m/%d/%Y')\n",
    "\n",
    "    # Format the datetime object into a new string structure\n",
    "    new_datetime_str = datetime_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    return new_datetime_str\n",
    "\n",
    "def haircut(df, date):\n",
    "    df[date] = df[date].str[:10]\n",
    "    return df\n",
    "\n",
    "def convert_date_format(df):\n",
    "    # Create a boolean mask to identify values in the \"m/d/y\" format\n",
    "    mask = df['Date'].str.contains(r'\\d{1,2}/\\d{1,2}/\\d{2}')\n",
    "    \n",
    "    # Apply the conversion only to values that match the mask\n",
    "    df.loc[mask, 'Date'] = nba.loc[mask, 'Date'].apply(date_change)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afc3c03b-ad79-4004-9c68-4810026f6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/liqingyang/Documents/GitHub/sports_trading/sports_betting/data/raw_data/NBA_2018_2024.csv\"\n",
    "df = pd.read_csv(folder_path, index_col=0)\n",
    "\n",
    "folder_path = \"/Users/liqingyang/Documents/GitHub/sports_trading/sports_betting/nba_api/data/teams_stats/processed_cumulative_season_stats_2019_2024.csv\"\n",
    "nba = pd.read_csv(folder_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82909c77-8a61-4ba2-b849-b555ade61839",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "find_team_exp_average_12() got an unexpected keyword argument 'include_groups'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m     \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03mApply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m    data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1341\u001b[0m, in \u001b[0;36mGroupBy.apply.<locals>.f\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: find_team_exp_average_12() got an unexpected keyword argument 'include_groups'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m df[valid_columns] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(df[valid_columns])\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# construct rolling features to df\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     35\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# construct current game metadata\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 75\u001b[0m, in \u001b[0;36mrolling\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     73\u001b[0m df_exp_rolling_9 \u001b[38;5;241m=\u001b[39m df_exp_rolling_9\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeams\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m'\u001b[39m], group_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mapply(find_team_exp_average_9)\n\u001b[1;32m     74\u001b[0m df_exp_rolling_12 \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;28mlist\u001b[39m(valid_columns) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeams\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m---> 75\u001b[0m df_exp_rolling_12 \u001b[38;5;241m=\u001b[39m \u001b[43mdf_exp_rolling_12\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTeams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseason\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_team_exp_average_12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m exp_rolling_columns_5 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_exp_5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_exp_rolling_5\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m     77\u001b[0m exp_rolling_columns_9 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_exp_9\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_exp_rolling_9\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1363\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj)\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[0;32m-> 1363\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_obj_with_exclusions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1375\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    769\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1341\u001b[0m, in \u001b[0;36mGroupBy.apply.<locals>.f\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(g):\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1341\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: find_team_exp_average_12() got an unexpected keyword argument 'include_groups'"
     ]
    }
   ],
   "source": [
    "# nba dataframe does not include the 2018 season\n",
    "df = df[~df['season'].isin([2018])]\n",
    "df = df.reset_index(drop=True)\n",
    "df = haircut(df, 'date')\n",
    "\n",
    "# rename nba columns to match df\n",
    "nba = haircut(nba, 'Date')\n",
    "nba = convert_date_format(nba)\n",
    "nba.rename(columns={'Date': 'date_next', 'Teams':'Teams_x'}, inplace=True)\n",
    "\n",
    "# construct winrate for team\n",
    "df = winrate(df)\n",
    "# construct differential points\n",
    "df = differential(df)\n",
    "# construct target\n",
    "df = df.groupby(\"Teams\", group_keys=False).apply(add_target)\n",
    "\n",
    "# games yet to play are 2\n",
    "df.loc[pd.isnull(df['target']), 'target'] = 2\n",
    "# convert win/loss to 1/0\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "# remove metadata and target\n",
    "removed = ['target', 'date', 'Teams_opp', 'Teams',\n",
    "           'season','won', 'Wins', 'Losses', \n",
    "           'Wins_opp', 'Losses_opp']\n",
    "valid_columns = df.columns[~df.columns.isin(removed)]\n",
    "\n",
    "# scale the data\n",
    "scaler = MinMaxScaler()\n",
    "df[valid_columns] = scaler.fit_transform(df[valid_columns])\n",
    "\n",
    "# construct rolling features to df\n",
    "df = rolling(df).copy()\n",
    "df = df.dropna()\n",
    "\n",
    "# construct current game metadata\n",
    "df['home_next'] = add_col(df, 'home')\n",
    "df['team_next_opp'] = add_col(df, 'Teams_opp')\n",
    "df['date_next'] = add_col(df, 'date')\n",
    "df = df.copy()\n",
    "\n",
    "# merge stats from opposing teams\n",
    "full = df.merge(df,\n",
    "               left_on=['Teams', 'date_next'],\n",
    "               right_on = ['team_next_opp', 'date_next'])\n",
    "\n",
    "# merge stats from nba dataframe\n",
    "complete = pd.merge(full, nba, on=['Teams_x', 'date_next'], how='left')\n",
    "complete = complete.dropna()\n",
    "\n",
    "# remove metadata and useless data\n",
    "disregard = list(complete.columns[complete.dtypes == 'object']) \n",
    "disregard = disregard + [\"home_opp_5_x\",\"target_x\",\"target_y\", \n",
    "                         \"Wins_x\", \"Losses_x\", \"Wins_opp_x\", \n",
    "                         \"Losses_opp_x\", \"season_x\" , \"won_x\" , \n",
    "                         \"home_5_x\" ,\"home_10_x\" ,\"season_5_x\", \n",
    "                         \"season_10_x\" , \"Wins_y\" , \"Losses_y\" , \n",
    "                         \"Wins_opp_y\" , \"Losses_opp_y\" , \"season_y\" , \n",
    "                         \"won_y\" ,\"home_5_y\", \"home_10_y\",\"season_5_y\", \n",
    "                         \"season_10_y\",\"home_opp_5_y\", \"home_opp_10_y\"]\n",
    "regard = complete.columns[~complete.columns.isin(disregard)]\n",
    "\n",
    "# remove metadata and useless data\n",
    "disregard_full = list(full.columns[full.dtypes == 'object']) \n",
    "disregard_full = disregard_full + [\"home_opp_5_x\",\"target_x\",\"target_y\", \n",
    "                         \"Wins_x\", \"Losses_x\", \"Wins_opp_x\", \n",
    "                         \"Losses_opp_x\", \"season_x\" , \"won_x\" , \n",
    "                         \"home_5_x\" ,\"home_10_x\" ,\"season_5_x\", \n",
    "                         \"season_10_x\" , \"Wins_y\" , \"Losses_y\" , \n",
    "                         \"Wins_opp_y\" , \"Losses_opp_y\" , \"season_y\" , \n",
    "                         \"won_y\" ,\"home_5_y\", \"home_10_y\",\"season_5_y\", \n",
    "                         \"season_10_y\",\"home_opp_5_y\", \"home_opp_10_y\"]\n",
    "regard_full = full.columns[~full.columns.isin(disregard_full)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c73899-50cc-4225-b905-780aae2ea483",
   "metadata": {},
   "outputs": [],
   "source": [
    "regard_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda96ef-1846-4b42-be40-b30bfd91094d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
